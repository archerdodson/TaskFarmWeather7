/scrtp/avon/eb/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Train SR network for lorenz96 model with lr 0.1 using EnergyScorePath scoring rule
  0%|          | 0/1000 [00:00<?, ?it/s]  0%|          | 1/1000 [01:09<19:18:52, 69.60s/it]  0%|          | 2/1000 [02:17<18:59:20, 68.50s/it]  0%|          | 3/1000 [03:25<18:53:45, 68.23s/it]  0%|          | 4/1000 [04:33<18:50:00, 68.07s/it]  0%|          | 5/1000 [05:41<18:48:15, 68.04s/it]  1%|          | 6/1000 [06:48<18:45:55, 67.96s/it]  1%|          | 7/1000 [07:56<18:44:56, 67.97s/it]  1%|          | 8/1000 [09:04<18:43:08, 67.93s/it]  1%|          | 9/1000 [10:12<18:42:13, 67.94s/it]  1%|          | 10/1000 [11:20<18:41:14, 67.95s/it]  1%|          | 11/1000 [12:28<18:40:21, 67.97s/it]  1%|          | 12/1000 [13:36<18:38:26, 67.92s/it]  1%|▏         | 13/1000 [14:44<18:37:25, 67.93s/it]  1%|▏         | 14/1000 [15:52<18:36:30, 67.94s/it]  2%|▏         | 15/1000 [17:00<18:35:34, 67.95s/it]  2%|▏         | 16/1000 [18:08<18:33:56, 67.92s/it]  2%|▏         | 17/1000 [19:16<18:32:56, 67.93s/it]  2%|▏         | 18/1000 [20:24<18:32:06, 67.95s/it]  2%|▏         | 19/1000 [21:32<18:31:15, 67.97s/it]  2%|▏         | 20/1000 [22:40<18:30:17, 67.98s/it]  2%|▏         | 21/1000 [23:48<18:29:17, 67.98s/it]  2%|▏         | 22/1000 [24:56<18:28:09, 67.99s/it]  2%|▏         | 23/1000 [26:04<18:27:11, 68.00s/it]  2%|▏         | 24/1000 [27:12<18:26:01, 67.99s/it]  2%|▎         | 25/1000 [28:20<18:24:50, 67.99s/it]  3%|▎         | 26/1000 [29:28<18:23:32, 67.98s/it]  3%|▎         | 27/1000 [30:36<18:22:44, 68.00s/it]  3%|▎         | 28/1000 [31:44<18:21:37, 68.00s/it]  3%|▎         | 29/1000 [32:52<18:20:22, 67.99s/it]  3%|▎         | 30/1000 [34:00<18:19:25, 68.01s/it]  3%|▎         | 31/1000 [35:08<18:18:12, 68.00s/it]  3%|▎         | 32/1000 [36:15<18:15:47, 67.92s/it]  3%|▎         | 33/1000 [37:23<18:11:40, 67.74s/it]  3%|▎         | 34/1000 [38:30<18:08:38, 67.62s/it]  4%|▎         | 35/1000 [39:38<18:08:15, 67.66s/it]  4%|▎         | 36/1000 [40:46<18:08:14, 67.73s/it]  4%|▎         | 37/1000 [41:54<18:08:01, 67.79s/it]  4%|▍         | 38/1000 [43:02<18:07:23, 67.82s/it]  4%|▍         | 39/1000 [44:09<18:06:26, 67.83s/it]  4%|▍         | 40/1000 [45:17<18:05:26, 67.84s/it]  4%|▍         | 41/1000 [46:25<18:04:38, 67.86s/it]  4%|▍         | 42/1000 [47:33<18:03:38, 67.87s/it]  4%|▍         | 43/1000 [48:41<18:02:59, 67.90s/it]  4%|▍         | 44/1000 [49:49<18:02:17, 67.93s/it]  4%|▍         | 45/1000 [50:57<17:59:27, 67.82s/it]  5%|▍         | 46/1000 [52:04<17:55:50, 67.66s/it]  5%|▍         | 47/1000 [53:11<17:53:08, 67.56s/it]  5%|▍         | 48/1000 [54:19<17:52:18, 67.58s/it]  5%|▍         | 49/1000 [55:27<17:53:03, 67.70s/it]  5%|▌         | 50/1000 [56:35<17:53:11, 67.78s/it]  5%|▌         | 51/1000 [57:43<17:52:57, 67.84s/it]  5%|▌         | 52/1000 [58:51<17:52:28, 67.88s/it]  5%|▌         | 53/1000 [59:59<17:51:50, 67.91s/it]  5%|▌         | 54/1000 [1:01:07<17:51:10, 67.94s/it]  6%|▌         | 55/1000 [1:02:15<17:50:15, 67.95s/it]  6%|▌         | 56/1000 [1:03:23<17:49:17, 67.96s/it]  6%|▌         | 57/1000 [1:04:31<17:48:10, 67.96s/it]  6%|▌         | 58/1000 [1:05:39<17:47:06, 67.97s/it]  6%|▌         | 59/1000 [1:06:47<17:46:10, 67.98s/it]  6%|▌         | 60/1000 [1:07:55<17:44:58, 67.98s/it]  6%|▌         | 61/1000 [1:09:03<17:44:01, 67.99s/it]  6%|▌         | 62/1000 [1:10:11<17:42:46, 67.98s/it]  6%|▋         | 63/1000 [1:11:19<17:41:35, 67.98s/it]  6%|▋         | 64/1000 [1:12:26<17:40:15, 67.97s/it]  6%|▋         | 65/1000 [1:13:34<17:39:06, 67.96s/it]  7%|▋         | 66/1000 [1:14:42<17:37:55, 67.96s/it]  7%|▋         | 67/1000 [1:15:50<17:36:59, 67.97s/it]  7%|▋         | 68/1000 [1:16:58<17:35:52, 67.98s/it]  7%|▋         | 69/1000 [1:18:06<17:34:45, 67.98s/it]  7%|▋         | 70/1000 [1:19:14<17:32:01, 67.87s/it]  7%|▋         | 71/1000 [1:20:21<17:27:13, 67.64s/it]  7%|▋         | 72/1000 [1:21:28<17:22:02, 67.37s/it]  7%|▋         | 73/1000 [1:22:34<17:16:08, 67.06s/it]  7%|▋         | 74/1000 [1:23Epoch: 1/1000. Train set: Average loss: 66.1844
Epoch: 1/1000. Validation set: Average loss: 24.6452
Epoch: 2/1000. Train set: Average loss: 25.4273
Epoch: 2/1000. Validation set: Average loss: 24.0926
Epoch: 3/1000. Train set: Average loss: 23.0556
Epoch: 3/1000. Validation set: Average loss: 21.2077
Epoch: 4/1000. Train set: Average loss: 20.6053
Epoch: 4/1000. Validation set: Average loss: 19.6072
Epoch: 5/1000. Train set: Average loss: 18.9374
Epoch: 5/1000. Validation set: Average loss: 17.9725
Epoch: 6/1000. Train set: Average loss: 17.5675
Epoch: 6/1000. Validation set: Average loss: 16.8075
Epoch: 7/1000. Train set: Average loss: 16.6824
Epoch: 7/1000. Validation set: Average loss: 16.8912
Epoch: 8/1000. Train set: Average loss: 16.6024
Epoch: 8/1000. Validation set: Average loss: 16.5794
Epoch: 9/1000. Train set: Average loss: 16.1607
Epoch: 9/1000. Validation set: Average loss: 16.2290
Epoch: 10/1000. Train set: Average loss: 16.0979
Epoch: 10/1000. Validation set: Average loss: 16.0912
Epoch: 11/1000. Train set: Average loss: 15.9544
Epoch: 11/1000. Validation set: Average loss: 16.0787
Epoch: 12/1000. Train set: Average loss: 16.2386
Epoch: 12/1000. Validation set: Average loss: 17.1762
Epoch: 13/1000. Train set: Average loss: 16.3360
Epoch: 13/1000. Validation set: Average loss: 16.2773
Epoch: 14/1000. Train set: Average loss: 16.2368
Epoch: 14/1000. Validation set: Average loss: 16.5969
Epoch: 15/1000. Train set: Average loss: 16.2642
Epoch: 15/1000. Validation set: Average loss: 16.1764
Epoch: 16/1000. Train set: Average loss: 15.9970
Epoch: 16/1000. Validation set: Average loss: 15.9803
Epoch: 17/1000. Train set: Average loss: 15.9006
Epoch: 17/1000. Validation set: Average loss: 16.5153
Epoch: 18/1000. Train set: Average loss: 16.1373
Epoch: 18/1000. Validation set: Average loss: 16.0366
Epoch: 19/1000. Train set: Average loss: 15.9816
Epoch: 19/1000. Validation set: Average loss: 15.9406
Epoch: 20/1000. Train set: Average loss: 15.8898
Epoch: 20/1000. Validation set: Average loss: 15.9387
Epoch: 21/1000. Train set: Average loss: 15.8782
Epoch: 21/1000. Validation set: Average loss: 16.3263
Epoch: 22/1000. Train set: Average loss: 16.4514
Epoch: 22/1000. Validation set: Average loss: 16.5622
Epoch: 23/1000. Train set: Average loss: 16.3944
Epoch: 23/1000. Validation set: Average loss: 17.0205
Epoch: 24/1000. Train set: Average loss: 16.7617
Epoch: 24/1000. Validation set: Average loss: 16.6230
Epoch: 25/1000. Train set: Average loss: 16.5076
Epoch: 25/1000. Validation set: Average loss: 16.7736
Epoch: 26/1000. Train set: Average loss: 16.2918
Epoch: 26/1000. Validation set: Average loss: 16.3929
Epoch: 27/1000. Train set: Average loss: 16.3818
Epoch: 27/1000. Validation set: Average loss: 16.4149
Epoch: 28/1000. Train set: Average loss: 16.2299
Epoch: 28/1000. Validation set: Average loss: 17.3096
Epoch: 29/1000. Train set: Average loss: 16.9137
Epoch: 29/1000. Validation set: Average loss: 16.3610
Epoch: 30/1000. Train set: Average loss: 16.7516
Epoch: 30/1000. Validation set: Average loss: 16.7734
Epoch: 31/1000. Train set: Average loss: 16.8319
Epoch: 31/1000. Validation set: Average loss: 16.5182
Epoch: 32/1000. Train set: Average loss: 16.6416
Epoch: 32/1000. Validation set: Average loss: 17.4789
Epoch: 33/1000. Train set: Average loss: 16.7448
Epoch: 33/1000. Validation set: Average loss: 16.5836
Epoch: 34/1000. Train set: Average loss: 16.7808
Epoch: 34/1000. Validation set: Average loss: 17.9021
Epoch: 35/1000. Train set: Average loss: 17.3396
Epoch: 35/1000. Validation set: Average loss: 17.0267
Epoch: 36/1000. Train set: Average loss: 16.9263
Epoch: 36/1000. Validation set: Average loss: 17.2257
Epoch: 37/1000. Train set: Average loss: 16.6744
Epoch: 37/1000. Validation set: Average loss: 16.4451
Epoch: 38/1000. Train set: Average loss: 16.6450
Epoch: 38/1000. Validation set: Average loss: 16.8648
Epoch: 39/1000. Train set: Average loss: 16.6766
Epoch: 39/1000. Validation set: Average loss: 16.5536
Epoch: 40/1000. Train set: Average loss: 16.8443
Epoch: 40/1000. Validation set: Average loss: 18.0599
Epoch: 41/1000. Train set: Average loss: 17.7779
Epoch: 41/1000. Validation set: Average loss: 20.1334
Epoch: 42/1000. Train set: Average loss: 18.2282
Epoch: 42/1000. Validation set: Average loss: 17.8957
Epoch: 43/1000. Train set: Average loss: 17.0978
Epoch: 43/1000. Validation set: Average loss: 16.7011
Epoch: 44/1000. Train set: Average loss: 17.4106
Epoch: 44/1000. Validation set: Average loss: 17.2761
Epoch: 45/1000. Train set: Average loss: 17.5266
Epoch: 45/1000. Validation set: Average loss: 17.2405
Epoch: 46/1000. Train set: Average loss: 16.7876
Epoch: 46/1000. Validation set: Average loss: 17.0589
Epoch: 47/1000. Train set: Average loss: 16.9500
Epoch: 47/1000. Validation set: Average loss: 16.6853
Epoch: 48/1000. Train set: Average loss: 16.6740
Epoch: 48/1000. Validation set: Average loss: 17.1141
Epoch: 49/1000. Train set: Average loss: 16.9638
Epoch: 49/1000. Validation set: Average loss: 16.5766
Epoch: 50/1000. Train set: Average loss: 16.7208
Epoch: 50/1000. Validation set: Average loss: 16.9900
Epoch: 51/1000. Train set: Average loss: 16.7294
Epoch: 51/1000. Validation set: Average loss: 17.0562
Epoch: 52/1000. Train set: Average loss: 16.6831
Epoch: 52/1000. Validation set: Average loss: 16.6679
Epoch: 53/1000. Train set: Average loss: 16.3729
Epoch: 53/1000. Validation set: Average loss: 16.6374
Epoch: 54/1000. Train set: Average loss: 17.5883
Epoch: 54/1000. Validation set: Average loss: 17.6712
Epoch: 55/1000. Train set: Average loss: 18.5004
Epoch: 55/1000. Validation set: Average loss: 19.0344
Epoch: 56/1000. Train set: Average loss: 18.6188
Epoch: 56/1000. Validation set: Average loss: 18.0686
Epoch: 57/1000. Train set: Average loss: 18.0028
Epoch: 57/1000. Validation set: Average loss: 18.0525
Epoch: 58/1000. Train set: Average loss: 17.5277
Epoch: 58/1000. Validation set: Average loss: 17.3231
Epoch: 59/1000. Train set: Average loss: 19.1110
Epoch: 59/1000. Validation set: Average loss: 18.8485
Epoch: 60/1000. Train set: Average loss: 17.7555
Epoch: 60/1000. Validation set: Average loss: 17.3715
Epoch: 61/1000. Train set: Average loss: 17.2135
Epoch: 61/1000. Validation set: Average loss: 17.8380
Epoch: 62/1000. Train set: Average loss: 17.3278
Epoch: 62/1000. Validation set: Average loss: 17.7081
Epoch: 63/1000. Train set: Average loss: 17.3810
Epoch: 63/1000. Validation set: Average loss: 17.3176
Epoch: 64/1000. Train set: Average loss: 17.0454
Epoch: 64/1000. Validation set: Average loss: 16.9765
Epoch: 65/1000. Train set: Average loss: 16.7667
Epoch: 65/1000. Validation set: Average loss: 17.0694
Epoch: 66/1000. Train set: Average loss: 16.5818
Epoch: 66/1000. Validation set: Average loss: 16.7168
Epoch: 67/1000. Train set: Average loss: 16.8509
Epoch: 67/1000. Validation set: Average loss: 16.6676
Epoch: 68/1000. Train set: Average loss: 16.4951
Epoch: 68/1000. Validation set: Average loss: 16.6994
Epoch: 69/1000. Train set: Average loss: 17.1383
Epoch: 69/1000. Validation set: Average loss: 17.3877
Epoch: 70/1000. Train set: Average loss: 17.1094
Epoch: 70/1000. Validation set: Average loss: 17.6065
Epoch: 71/1000. Train set: Average loss: 17.0058
Epoch: 71/1000. Validation set: Average loss: 17.0511
Epoch: 72/1000. Train set: Average loss: 16.3496
Epoch: 72/1000. Validation set: Average loss: 16.1415
Epoch: 73/1000. Train set: Average loss: 16.1489
Epoch: 73/1000. Validation set: Average loss: 16.9270
Epoch: 74/1000. Train set: Average loss: 16.2760
Epoch: 74/1000. Validation set: Average loss: 18.5426
Epoch: 75/1000. Train set: Average loss: 16.6255
Epoch: 75/1000. Validation set: Average loss: 16.2070
Epoch: 76/1000. Train set: Average loss: 16.1891
Epoch: 76/1000. Validation set: Average loss: 16.5238
Epoch: 77/1000. Train set: Average loss: 16.3455
Epoch: 77/1000. Validation set: Average loss: 16.4936
Epoch: 78/1000. Train set: Average loss: 16.3814
Epoch: 78/1000. Validation set: Average loss: 16.4048
Epoch: 79/1000. Train set: Average loss: 16.1911
Epoch: 79/1000. Validation set: Average loss: 16.2537
Epoch: 80/1000. Train set: Average loss: 16.0476
:40<17:10:04, 66.74s/it]  8%|▊         | 75/1000 [1:24:46<17:03:45, 66.41s/it]  8%|▊         | 76/1000 [1:25:51<16:57:49, 66.09s/it]  8%|▊         | 77/1000 [1:26:56<16:53:09, 65.86s/it]  8%|▊         | 78/1000 [1:28:02<16:49:39, 65.70s/it]  8%|▊         | 79/1000 [1:29:07<16:47:00, 65.60s/it]  8%|▊         | 80/1000 [1:30:13<16:44:41, 65.52s/it]  8%|▊         | 81/1000 [1:31:18<16:43:23, 65.51s/it]  8%|▊         | 82/1000 [1:32:23<16:41:57, 65.49s/it]  8%|▊         | 83/1000 [1:33:29<16:40:46, 65.48s/it]  8%|▊         | 84/1000 [1:34:35<16:40:58, 65.57s/it]  8%|▊         | 85/1000 [1:35:40<16:40:42, 65.62s/it]  9%|▊         | 86/1000 [1:36:46<16:40:14, 65.66s/it]  9%|▊         | 87/1000 [1:37:52<16:39:37, 65.69s/it]  9%|▉         | 88/1000 [1:38:58<16:38:42, 65.70s/it]  9%|▉         | 89/1000 [1:40:03<16:37:57, 65.73s/it]  9%|▉         | 90/1000 [1:41:09<16:37:04, 65.74s/it]  9%|▉         | 91/1000 [1:42:15<16:36:10, 65.75s/it]  9%|▉         | 92/1000 [1:43:21<16:34:23, 65.71s/it]  9%|▉         | 93/1000 [1:44:26<16:32:22, 65.65s/it]  9%|▉         | 94/1000 [1:45:31<16:30:07, 65.57s/it] 10%|▉         | 95/1000 [1:46:37<16:28:00, 65.50s/it] 10%|▉         | 96/1000 [1:47:42<16:26:29, 65.48s/it] 10%|▉         | 97/1000 [1:48:48<16:25:07, 65.46s/it] 10%|▉         | 98/1000 [1:49:53<16:23:56, 65.45s/it] 10%|▉         | 99/1000 [1:50:58<16:22:36, 65.43s/it] 10%|▉         | 99/1000 [1:52:04<16:59:58, 67.92s/it]
Epoch: 80/1000. Validation set: Average loss: 16.3015
Epoch: 81/1000. Train set: Average loss: 16.1622
Epoch: 81/1000. Validation set: Average loss: 16.4323
Epoch: 82/1000. Train set: Average loss: 17.9346
Epoch: 82/1000. Validation set: Average loss: 17.6940
Epoch: 83/1000. Train set: Average loss: 16.9370
Epoch: 83/1000. Validation set: Average loss: 16.6834
Epoch: 84/1000. Train set: Average loss: 16.5850
Epoch: 84/1000. Validation set: Average loss: 16.8864
Epoch: 85/1000. Train set: Average loss: 16.4740
Epoch: 85/1000. Validation set: Average loss: 16.4858
Epoch: 86/1000. Train set: Average loss: 16.1688
Epoch: 86/1000. Validation set: Average loss: 16.1279
Epoch: 87/1000. Train set: Average loss: 16.2098
Epoch: 87/1000. Validation set: Average loss: 16.2044
Epoch: 88/1000. Train set: Average loss: 16.0934
Epoch: 88/1000. Validation set: Average loss: 16.4295
Epoch: 89/1000. Train set: Average loss: 16.0760
Epoch: 89/1000. Validation set: Average loss: 16.5588
Epoch: 90/1000. Train set: Average loss: 16.2187
Epoch: 90/1000. Validation set: Average loss: 15.9123
Epoch: 91/1000. Train set: Average loss: 15.9731
Epoch: 91/1000. Validation set: Average loss: 16.2179
Epoch: 92/1000. Train set: Average loss: 16.2984
Epoch: 92/1000. Validation set: Average loss: 16.5368
Epoch: 93/1000. Train set: Average loss: 16.2837
Epoch: 93/1000. Validation set: Average loss: 16.6176
Epoch: 94/1000. Train set: Average loss: 16.4005
Epoch: 94/1000. Validation set: Average loss: 16.9921
Epoch: 95/1000. Train set: Average loss: 16.4416
Epoch: 95/1000. Validation set: Average loss: 16.2445
Epoch: 96/1000. Train set: Average loss: 16.1482
Epoch: 96/1000. Validation set: Average loss: 16.2225
Epoch: 97/1000. Train set: Average loss: 16.1418
Epoch: 97/1000. Validation set: Average loss: 16.4462
Epoch: 98/1000. Train set: Average loss: 16.3482
Epoch: 98/1000. Validation set: Average loss: 17.0692
Epoch: 99/1000. Train set: Average loss: 16.2975
Epoch: 99/1000. Validation set: Average loss: 16.1717
Epoch: 100/1000. Train set: Average loss: 16.0367
Epoch: 100/1000. Validation set: Average loss: 16.4740
yo?
Training time: 6731.70 seconds
Initial Window: tensor([[-6.6552,  0.5743, -2.0714,  4.9840,  8.8309, -1.0462,  4.6527, 10.7432],
        [-1.2573,  7.1192, 11.5621,  6.1425,  4.6180,  2.1320,  6.4135,  6.0790],
        [ 2.6308,  9.7157, 10.4960, -4.0719,  4.2621,  7.6632,  8.4280,  2.7578],
        [ 3.5314, 11.6621, -4.1574, -0.8401, -0.3725, 13.6223,  2.9777, -2.3032],
        [ 5.1709, 10.8603,  1.5052,  5.3575, 10.2030,  5.3154, -5.2997,  2.4698],
        [10.5231,  9.8095, -0.6279,  6.6502,  6.5805, -5.7486,  2.8205,  3.1672],
        [ 5.0987, -6.5853,  0.9564,  8.1044,  2.5500, -3.7802,  1.2906, 13.2256],
        [-0.7764,  0.9630, -1.0545,  8.2193,  2.7532, -1.9499, -0.7012, 13.0293],
        [ 4.3098, -1.4679,  3.2837,  9.0329, -0.0238, -0.2983,  0.3141, 12.5709],
        [-3.2271,  1.6273,  3.9535, 10.1696,  0.9897,  3.0876,  6.8140, 10.1955]])
Next 10 (9 prediction_length) steps tensor([[-3.2271,  1.6273,  3.9535, 10.1696,  0.9897,  3.0876,  6.8140, 10.1955],
        [-2.4412,  1.4171, 11.8924,  5.5080, -2.5457,  4.1696, 10.3193, -1.5410],
        [ 4.4459,  8.1026,  9.1760, -3.9613,  0.8670,  3.4818, 10.2734, -0.1379],
        [ 5.9674,  8.7886, -4.9083, -0.0667,  0.8987,  9.6319,  9.1128, -0.1576],
        [ 6.9344,  4.8333, -3.8852,  3.3546, 11.8590,  8.3064, -3.2138,  0.3050],
        [ 8.4130,  2.1772, -2.3242,  0.2615, 13.1742, -2.2076,  0.1661, -0.2565],
        [ 8.4880, -1.0374,  0.9322,  1.5652, 12.9802,  4.5080,  0.3643,  4.7071],
        [ 7.4834, -0.7099,  4.0739, 10.1310,  8.0202, -4.6900,  2.4052,  7.3596],
        [ 4.5218, -1.9389,  4.2597, 10.7186, -4.9986,  2.3751,  1.0690, 10.4754],
        [-3.4356,  0.8486,  5.4150, 10.1238,  1.6039,  6.4489, 11.1378,  0.3445]])
predicted output from the model tensor([[[ 0.3478,  1.0935,  5.2699,  6.0850, -0.8562,  2.6199,  5.6044,
           7.3394],
         [ 2.3224,  2.9810,  9.7868, -0.1682,  2.5940,  3.7053,  9.8798,
          -0.2973]],

        [[ 0.7888,  1.9668,  6.3619,  3.1307, -1.1587,  3.8907,  6.4980,
           4.7070],
         [ 1.9418,  7.3865,  7.8806, -2.4640,  2.6679,  7.4709,  8.3278,
          -2.4273]],

        [[ 2.0729,  2.6103,  9.0386,  0.7317,  1.7406,  3.6446,  9.1477,
           0.9883],
         [19.8135, -2.5122, -5.8251, -1.2475, 17.0443, -0.5502, -2.4245,
           4.9629]]], device='cuda:0', grad_fn=<CatBackward0>) torch.Size([3, 2, 8])
val_loss_list [24.645160653162748, 24.09264288796112, 21.207740591838956, 19.607210371643305, 17.972487153252587, 16.807457899674773, 16.891159594757482, 16.579401190858334, 16.228970563737676, 16.091156736481935, 16.078690400812775, 17.176238970598206, 16.27727831772063, 16.59692370542325, 16.176399583695456, 15.98033584957011, 16.51527920179069, 16.036615842371248, 15.940600469475612, 15.938735177041963, 16.326264451956376, 16.562192991841584, 17.02045872923918, 16.62304875906557, 16.773630307987332, 16.39288989827037, 16.41490647266619, 17.30958045902662, 16.36104268557392, 16.773423878941685, 16.518209791043773, 17.478907097596675, 16.583591320551932, 17.902130043366924, 17.026683445554227, 17.225669995183125, 16.445060075027868, 16.864838329143822, 16.553571987431496, 18.059935079421848, 20.133434154326096, 17.895691523794085, 16.7011172096245, 17.276091078063473, 17.240485806250945, 17.058919886127114, 16.685304309474304, 17.114115003030747, 16.576556055573747, 16.990043877856806, 17.056232038885355, 16.667876892723143, 16.637448810506612, 17.671227735467255, 19.03444771352224, 18.068618554621935, 18.05250340560451, 17.323073776206, 18.848540636477992, 17.371518111787736, 17.837966356426477, 17.708067891420797, 17.31757626752369, 16.976532691158354, 17.06937852012925, 16.716821355978027, 16.66757205245085, 16.69935686979443, 17.387743250234053, 17.60654352698475, 17.051124093821272, 16.14152911072597, 16.926995057845488, 18.542559668421745, 16.20703931991011, 16.523803954012692, 16.493647194467485, 16.404793585650623, 16.25369067233987, 16.301495915744454, 16.432296333368868, 17.69399932725355, 16.683436312247068, 16.886410887353122, 16.4857891574502, 16.127924980595708, 16.204400151968002, 16.4294885864947, 16.558807274559513, 15.912252933485433, 16.217872804496437, 16.536807079333812, 16.61759020597674, 16.992080450523645, 16.24452209402807, 16.222501365933567, 16.44623460713774, 17.069188373861834, 16.171736891614273, 16.474037299165502]
16.6281131869182
