/scrtp/avon/eb/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Train SR network for lorenz96 model with lr 0.01 using SignatureKernel scoring rule
  0%|          | 0/1000 [00:00<?, ?it/s]/gpfs/home/stats/stubxk/ArcherDissEnv3/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: [1mGrid size 9 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/gpfs/home/stats/stubxk/ArcherDissEnv3/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: [1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
  0%|          | 1/1000 [05:52<97:43:04, 352.14s/it]  0%|          | 2/1000 [11:42<97:24:21, 351.36s/it]  0%|          | 3/1000 [17:33<97:14:05, 351.10s/it]  0%|          | 4/1000 [23:24<97:05:00, 350.90s/it]  0%|          | 5/1000 [29:54<100:51:07, 364.89s/it]  1%|          | 6/1000 [36:28<103:32:52, 375.02s/it]  1%|          | 7/1000 [42:59<104:50:08, 380.07s/it]  1%|          | 8/1000 [49:29<105:39:48, 383.46s/it]  1%|          | 9/1000 [56:01<106:14:35, 385.95s/it]  1%|          | 10/1000 [1:02:32<106:36:41, 387.68s/it]  1%|          | 11/1000 [1:09:04<106:48:06, 388.76s/it]  1%|          | 12/1000 [1:15:35<106:55:31, 389.61s/it]  1%|â–         | 13/1000 [1:22:07<106:58:11, 390.16s/it]  1%|â–         | 14/1000 [1:28:38<106:57:20, 390.51s/it]  2%|â–         | 15/1000 [1:35:09<106:54:59, 390.76s/it]  2%|â–         | 16/1000 [1:41:41<106:51:54, 390.97s/it]  2%|â–         | 17/1000 [1:48:12<106:46:14, 391.02s/it]  2%|â–         | 18/1000 [1:54:43<106:42:15, 391.18s/it]  2%|â–         | 19/1000 [2:01:15<106:35:42, 391.17s/it]  2%|â–         | 20/1000 [2:07:46<106:29:25, 391.19s/it]  2%|â–         | 21/1000 [2:14:17<106:22:51, 391.19s/it]  2%|â–         | 22/1000 [2:20:48<106:16:25, 391.19s/it]  2%|â–         | 23/1000 [2:27:20<106:11:37, 391.30s/it]  2%|â–         | 24/1000 [2:33:51<106:04:31, 391.26s/it]  2%|â–Ž         | 25/1000 [2:40:22<105:58:02, 391.26s/it]  3%|â–Ž         | 26/1000 [2:46:53<105:51:43, 391.28s/it]  3%|â–Ž         | 27/1000 [2:53:25<105:45:06, 391.27s/it]  3%|â–Ž         | 28/1000 [2:59:56<105:39:00, 391.30s/it]  3%|â–Ž         | 29/1000 [3:06:27<105:32:04, 391.27s/it]  3%|â–Ž         | 30/1000 [3:12:59<105:25:24, 391.26s/it]  3%|â–Ž         | 31/1000 [3:19:30<105:18:00, 391.21s/it]  3%|â–Ž         | 32/1000 [3:26:00<105:08:09, 391.00s/it]  3%|â–Ž         | 33/1000 [3:32:32<105:06:53, 391.33s/it]  3%|â–Ž         | 34/1000 [3:39:02<104:52:29, 390.84s/it]  4%|â–Ž         | 35/1000 [3:45:32<104:40:27, 390.50s/it]  4%|â–Ž         | 36/1000 [3:52:04<104:41:33, 390.97s/it]  4%|â–Ž         | 37/1000 [3:58:36<104:41:41, 391.38s/it]  4%|â–         | 38/1000 [4:05:08<104:40:18, 391.70s/it]  4%|â–         | 39/1000 [4:11:41<104:35:29, 391.81s/it]  4%|â–         | 40/1000 [4:18:13<104:30:08, 391.88s/it]  4%|â–         | 41/1000 [4:24:45<104:26:02, 392.04s/it]  4%|â–         | 42/1000 [4:31:17<104:21:21, 392.15s/it]  4%|â–         | 43/1000 [4:37:50<104:17:54, 392.35s/it]  4%|â–         | 44/1000 [4:44:23<104:11:31, 392.35s/it]  4%|â–         | 45/1000 [4:50:55<104:05:20, 392.38s/it]  5%|â–         | 46/1000 [4:57:27<103:59:13, 392.40s/it]  5%|â–         | 47/1000 [5:04:00<103:53:15, 392.44s/it]  5%|â–         | 48/1000 [5:10:32<103:46:43, 392.44s/it]  5%|â–         | 49/1000 [5:17:05<103:40:51, 392.48s/it]  5%|â–Œ         | 50/1000 [5:23:38<103:34:27, 392.49s/it]  5%|â–Œ         | 51/1000 [5:30:10<103:27:13, 392.45s/it]  5%|â–Œ         | 52/1000 [5:36:42<103:20:36, 392.44s/it]  5%|â–Œ         | 53/1000 [5:43:15<103:13:55, 392.43s/it]  5%|â–Œ         | 54/1000 [5:49:47<103:06:28, 392.38s/it]  6%|â–Œ         | 55/1000 [5:56:19<102:59:55, 392.38s/it]  6%|â–Œ         | 56/1000 [6:02:51<102:51:22, 392.25s/it]  6%|â–Œ         | 57/1000 [6:09:24<102:45:03, 392.26s/it]  6%|â–Œ         | 58/1000 [6:15:56<102:39:55, 392.35s/it]  6%|â–Œ         | 59/1000 [6:22:28<102:32:24, 392.29s/it]  6%|â–Œ         | 60/1000 [6:29:00<102:24:50, 392.22s/it]  6%|â–Œ         | 61/1000 [6:35:33<102:18:12, 392.22s/it]  6%|â–Œ         | 62/1000 [6:42:05<102:11:53, 392.23s/it]  6%|â–‹         | 63/1000 [6:48:37<102:05:54, 392.27s/it]  6%|â–‹         | 64/1000 [6:55:09<101:58:26, 392.21s/it]  6%|â–‹         | 65/1000 [7:01:41<101:51:07, 392.16s/it]  7%|â–‹         | 66/1000 [7:08:13<101:44:40, 392.16s/it]  7%|â–‹         | 67/1000 [7:14:46<101:39:07, 392.23s/it]  7%|â–‹         | 68/1000 [7:21:18<101:33:18, 392.27s/it]  7%|â–‹         | 69/1000 [7:27:50<101:26:31, 392.26s/it]  7%|â–‹         | 70/1000 [7:34:23<101:19:57, 392.26s/it]  7%|â–‹         | 7Epoch: 1/1000. Train set: Average loss: 2.0931
Epoch: 1/1000. Validation set: Average loss: 0.2703
Epoch: 2/1000. Train set: Average loss: -0.4189
Epoch: 2/1000. Validation set: Average loss: -0.5897
Epoch: 3/1000. Train set: Average loss: -0.5842
Epoch: 3/1000. Validation set: Average loss: -0.5937
Epoch: 4/1000. Train set: Average loss: -0.6134
Epoch: 4/1000. Validation set: Average loss: -0.5943
Epoch: 5/1000. Train set: Average loss: -0.6187
Epoch: 5/1000. Validation set: Average loss: -0.6150
Epoch: 6/1000. Train set: Average loss: -0.6273
Epoch: 6/1000. Validation set: Average loss: -0.6146
Epoch: 7/1000. Train set: Average loss: -0.6257
Epoch: 7/1000. Validation set: Average loss: -0.6106
Epoch: 8/1000. Train set: Average loss: -0.6228
Epoch: 8/1000. Validation set: Average loss: -0.6131
Epoch: 9/1000. Train set: Average loss: -0.6268
Epoch: 9/1000. Validation set: Average loss: -0.6173
Epoch: 10/1000. Train set: Average loss: -0.6369
Epoch: 10/1000. Validation set: Average loss: -0.6676
Epoch: 11/1000. Train set: Average loss: -0.7216
Epoch: 11/1000. Validation set: Average loss: -0.8179
Epoch: 12/1000. Train set: Average loss: -0.9630
Epoch: 12/1000. Validation set: Average loss: -1.2415
Epoch: 13/1000. Train set: Average loss: 0.6867
Epoch: 13/1000. Validation set: Average loss: 2.9564
Epoch: 14/1000. Train set: Average loss: 2.4855
Epoch: 14/1000. Validation set: Average loss: 1.2150
Epoch: 15/1000. Train set: Average loss: 0.1973
Epoch: 15/1000. Validation set: Average loss: -0.4811
Epoch: 16/1000. Train set: Average loss: -0.5607
Epoch: 16/1000. Validation set: Average loss: -0.6063
Epoch: 17/1000. Train set: Average loss: -0.6272
Epoch: 17/1000. Validation set: Average loss: -0.6986
Epoch: 18/1000. Train set: Average loss: -0.7590
Epoch: 18/1000. Validation set: Average loss: -0.8522
Epoch: 19/1000. Train set: Average loss: -0.9397
Epoch: 19/1000. Validation set: Average loss: -0.9557
Epoch: 20/1000. Train set: Average loss: -0.9882
Epoch: 20/1000. Validation set: Average loss: -0.9632
Epoch: 21/1000. Train set: Average loss: -1.0985
Epoch: 21/1000. Validation set: Average loss: -1.1934
Epoch: 22/1000. Train set: Average loss: -1.3265
Epoch: 22/1000. Validation set: Average loss: -1.5915
Epoch: 23/1000. Train set: Average loss: -1.9898
Epoch: 23/1000. Validation set: Average loss: -2.2430
Epoch: 24/1000. Train set: Average loss: -2.2543
Epoch: 24/1000. Validation set: Average loss: -2.2575
Epoch: 25/1000. Train set: Average loss: -2.2604
Epoch: 25/1000. Validation set: Average loss: -2.2617
Epoch: 26/1000. Train set: Average loss: -2.2598
Epoch: 26/1000. Validation set: Average loss: -2.2641
Epoch: 27/1000. Train set: Average loss: -2.2614
Epoch: 27/1000. Validation set: Average loss: -2.2603
Epoch: 28/1000. Train set: Average loss: -2.2567
Epoch: 28/1000. Validation set: Average loss: -2.2563
Epoch: 29/1000. Train set: Average loss: -2.2589
Epoch: 29/1000. Validation set: Average loss: -2.2579
Epoch: 30/1000. Train set: Average loss: -2.2653
Epoch: 30/1000. Validation set: Average loss: -2.2661
Epoch: 31/1000. Train set: Average loss: -2.2635
Epoch: 31/1000. Validation set: Average loss: -2.2628
Epoch: 32/1000. Train set: Average loss: -2.2646
Epoch: 32/1000. Validation set: Average loss: -2.2655
Epoch: 33/1000. Train set: Average loss: -2.2693
Epoch: 33/1000. Validation set: Average loss: -2.2702
Epoch: 34/1000. Train set: Average loss: -2.2664
Epoch: 34/1000. Validation set: Average loss: -2.2715
Epoch: 35/1000. Train set: Average loss: -2.2667
Epoch: 35/1000. Validation set: Average loss: -2.2628
Epoch: 36/1000. Train set: Average loss: -2.2655
Epoch: 36/1000. Validation set: Average loss: -2.2649
Epoch: 37/1000. Train set: Average loss: -2.2538
Epoch: 37/1000. Validation set: Average loss: -2.2390
Epoch: 38/1000. Train set: Average loss: -2.2434
Epoch: 38/1000. Validation set: Average loss: -2.2507
Epoch: 39/1000. Train set: Average loss: -2.2561
Epoch: 39/1000. Validation set: Average loss: -2.2565
Epoch: 40/1000. Train set: Average loss: -2.2595
Epoch: 40/1000. Validation set: Average loss: -2.2664
Epoch: 41/1000. Train set: Average loss: -2.2655
Epoch: 41/1000. Validation set: Average loss: -2.2649
Epoch: 42/1000. Train set: Average loss: -2.2658
Epoch: 42/1000. Validation set: Average loss: -2.2642
Epoch: 43/1000. Train set: Average loss: -2.2667
Epoch: 43/1000. Validation set: Average loss: -2.2669
Epoch: 44/1000. Train set: Average loss: -2.2661
Epoch: 44/1000. Validation set: Average loss: -2.2644
Epoch: 45/1000. Train set: Average loss: -2.2668
Epoch: 45/1000. Validation set: Average loss: -2.2676
Epoch: 46/1000. Train set: Average loss: -2.2683
Epoch: 46/1000. Validation set: Average loss: -2.2654
Epoch: 47/1000. Train set: Average loss: -2.2690
Epoch: 47/1000. Validation set: Average loss: -2.2694
Epoch: 48/1000. Train set: Average loss: -2.2702
Epoch: 48/1000. Validation set: Average loss: -2.2694
Epoch: 49/1000. Train set: Average loss: -2.2707
Epoch: 49/1000. Validation set: Average loss: -2.2725
Epoch: 50/1000. Train set: Average loss: -2.2722
Epoch: 50/1000. Validation set: Average loss: -2.2700
Epoch: 51/1000. Train set: Average loss: -2.2716
Epoch: 51/1000. Validation set: Average loss: -2.2672
Epoch: 52/1000. Train set: Average loss: -2.2687
Epoch: 52/1000. Validation set: Average loss: -2.2712
Epoch: 53/1000. Train set: Average loss: -2.2691
Epoch: 53/1000. Validation set: Average loss: -2.2696
Epoch: 54/1000. Train set: Average loss: -2.2719
Epoch: 54/1000. Validation set: Average loss: -2.2721
Epoch: 55/1000. Train set: Average loss: -2.2751
Epoch: 55/1000. Validation set: Average loss: -2.2765
Epoch: 56/1000. Train set: Average loss: -2.2760
Epoch: 56/1000. Validation set: Average loss: -2.2767
Epoch: 57/1000. Train set: Average loss: -2.2753
Epoch: 57/1000. Validation set: Average loss: -2.2755
Epoch: 58/1000. Train set: Average loss: -2.2759
Epoch: 58/1000. Validation set: Average loss: -2.2760
Epoch: 59/1000. Train set: Average loss: -2.2742
Epoch: 59/1000. Validation set: Average loss: -2.2752
Epoch: 60/1000. Train set: Average loss: -2.2740
Epoch: 60/1000. Validation set: Average loss: -2.2754
Epoch: 61/1000. Train set: Average loss: -2.2754
Epoch: 61/1000. Validation set: Average loss: -2.2741
Epoch: 62/1000. Train set: Average loss: -2.2764
Epoch: 62/1000. Validation set: Average loss: -2.2780
Epoch: 63/1000. Train set: Average loss: -2.2742
Epoch: 63/1000. Validation set: Average loss: -2.2593
Epoch: 64/1000. Train set: Average loss: -2.2464
Epoch: 64/1000. Validation set: Average loss: -2.2767
Epoch: 65/1000. Train set: Average loss: -2.2787
Epoch: 65/1000. Validation set: Average loss: -2.2792
Epoch: 66/1000. Train set: Average loss: -2.2791
Epoch: 66/1000. Validation set: Average loss: -2.2788
Epoch: 67/1000. Train set: Average loss: -2.2786
Epoch: 67/1000. Validation set: Average loss: -2.2783
Epoch: 68/1000. Train set: Average loss: -2.2793
Epoch: 68/1000. Validation set: Average loss: -2.2790
Epoch: 69/1000. Train set: Average loss: -2.2794
Epoch: 69/1000. Validation set: Average loss: -2.2783
Epoch: 70/1000. Train set: Average loss: -2.2789
Epoch: 70/1000. Validation set: Average loss: -2.2782
Epoch: 71/1000. Train set: Average loss: -2.2792
Epoch: 71/1000. Validation set: Average loss: -2.2789
Epoch: 72/1000. Train set: Average loss: -2.2788
Epoch: 72/1000. Validation set: Average loss: -2.2777
Epoch: 73/1000. Train set: Average loss: -2.2794
Epoch: 73/1000. Validation set: Average loss: -2.2786
Epoch: 74/1000. Train set: Average loss: -2.2791
Epoch: 74/1000. Validation set: Average loss: -2.2782
Epoch: 75/1000. Train set: Average loss: -2.2790
Epoch: 75/1000. Validation set: Average loss: -2.2787
Epoch: 76/1000. Train set: Average loss: -2.2786
Epoch: 76/1000. Validation set: Average loss: -2.2792
Epoch: 77/1000. Train set: Average loss: -2.2788
Epoch: 77/1000. Validation set: Average loss: -2.2788
Epoch: 78/1000. Train set: Average loss: -2.2789
Epoch: 78/1000. Validation set: Average loss: -2.2792
Epoch: 79/1000. Train set: Average loss: -2.2791
Epoch: 79/1000. Validation set: Average loss: -2.2791
Epoch: 80/1000. Train set: Average loss: -2.2790
1/1000 [7:40:55<101:13:55, 392.29s/it]  7%|â–‹         | 72/1000 [7:47:27<101:06:57, 392.26s/it]  7%|â–‹         | 73/1000 [7:53:59<101:00:09, 392.24s/it]  7%|â–‹         | 74/1000 [8:00:31<100:52:39, 392.18s/it]  8%|â–Š         | 75/1000 [8:07:04<100:46:45, 392.22s/it]  8%|â–Š         | 76/1000 [8:13:36<100:39:58, 392.21s/it]  8%|â–Š         | 77/1000 [8:20:08<100:33:42, 392.22s/it]  8%|â–Š         | 78/1000 [8:26:41<100:28:15, 392.29s/it]  8%|â–Š         | 79/1000 [8:33:13<100:21:37, 392.29s/it]  8%|â–Š         | 80/1000 [8:39:45<100:14:01, 392.22s/it]  8%|â–Š         | 81/1000 [8:46:17<100:05:01, 392.06s/it]  8%|â–Š         | 82/1000 [8:52:49<99:58:16, 392.04s/it]   8%|â–Š         | 83/1000 [8:59:21<99:52:25, 392.09s/it]  8%|â–Š         | 84/1000 [9:05:53<99:47:06, 392.17s/it]  8%|â–Š         | 85/1000 [9:12:26<99:40:55, 392.19s/it]  9%|â–Š         | 86/1000 [9:18:58<99:34:44, 392.21s/it]  9%|â–Š         | 87/1000 [9:25:30<99:28:41, 392.25s/it]  9%|â–‰         | 88/1000 [9:32:02<99:22:20, 392.26s/it]  9%|â–‰         | 89/1000 [9:38:34<99:15:05, 392.21s/it]  9%|â–‰         | 90/1000 [9:45:07<99:08:24, 392.20s/it]  9%|â–‰         | 91/1000 [9:51:39<99:01:33, 392.18s/it]  9%|â–‰         | 92/1000 [9:58:11<98:54:14, 392.13s/it]  9%|â–‰         | 93/1000 [10:04:43<98:48:47, 392.20s/it]  9%|â–‰         | 94/1000 [10:11:15<98:41:57, 392.18s/it] 10%|â–‰         | 95/1000 [10:17:47<98:35:05, 392.16s/it] 10%|â–‰         | 96/1000 [10:24:20<98:28:37, 392.17s/it] 10%|â–‰         | 97/1000 [10:30:52<98:21:32, 392.13s/it] 10%|â–‰         | 98/1000 [10:37:24<98:15:45, 392.18s/it] 10%|â–‰         | 99/1000 [10:43:12<94:49:48, 378.90s/it] 10%|â–ˆ         | 100/1000 [10:48:58<92:15:38, 369.04s/it] 10%|â–ˆ         | 101/1000 [10:54:44<90:27:19, 362.22s/it] 10%|â–ˆ         | 102/1000 [11:00:30<89:09:36, 357.43s/it] 10%|â–ˆ         | 103/1000 [11:06:17<88:15:02, 354.18s/it] 10%|â–ˆ         | 104/1000 [11:12:03<87:29:58, 351.56s/it] 10%|â–ˆ         | 105/1000 [11:17:48<86:54:51, 349.60s/it] 11%|â–ˆ         | 106/1000 [11:23:32<86:27:02, 348.12s/it] 11%|â–ˆ         | 107/1000 [11:29:17<86:06:20, 347.12s/it] 11%|â–ˆ         | 108/1000 [11:35:02<85:50:10, 346.42s/it] 11%|â–ˆ         | 109/1000 [11:40:47<85:37:01, 345.93s/it] 11%|â–ˆ         | 110/1000 [11:46:31<85:26:26, 345.60s/it] 11%|â–ˆ         | 111/1000 [11:52:16<85:17:37, 345.40s/it] 11%|â–ˆ         | 112/1000 [11:58:01<85:10:12, 345.28s/it] 11%|â–ˆâ–        | 113/1000 [12:03:47<85:08:07, 345.53s/it] 11%|â–ˆâ–        | 114/1000 [12:09:33<85:04:02, 345.65s/it] 12%|â–ˆâ–        | 115/1000 [12:15:17<84:49:40, 345.06s/it] 12%|â–ˆâ–        | 116/1000 [12:21:01<84:38:24, 344.69s/it] 12%|â–ˆâ–        | 117/1000 [12:26:45<84:28:28, 344.40s/it] 12%|â–ˆâ–        | 118/1000 [12:32:29<84:20:24, 344.25s/it] 12%|â–ˆâ–        | 119/1000 [12:38:12<84:11:43, 344.04s/it] 12%|â–ˆâ–        | 120/1000 [12:43:56<84:03:47, 343.90s/it] 12%|â–ˆâ–        | 121/1000 [12:49:39<83:57:25, 343.85s/it] 12%|â–ˆâ–        | 122/1000 [12:55:23<83:50:50, 343.79s/it] 12%|â–ˆâ–        | 123/1000 [13:01:13<84:13:22, 345.73s/it] 12%|â–ˆâ–        | 124/1000 [13:07:03<84:26:06, 346.99s/it] 12%|â–ˆâ–Ž        | 125/1000 [13:12:53<84:32:44, 347.84s/it] 13%|â–ˆâ–Ž        | 126/1000 [13:19:18<87:09:08, 358.98s/it] 13%|â–ˆâ–Ž        | 127/1000 [13:25:51<89:32:34, 369.25s/it] 13%|â–ˆâ–Ž        | 128/1000 [13:32:24<91:08:10, 376.25s/it] 13%|â–ˆâ–Ž        | 129/1000 [13:38:57<92:15:00, 381.29s/it] 13%|â–ˆâ–Ž        | 130/1000 [13:44:43<89:33:52, 370.61s/it] 13%|â–ˆâ–Ž        | 131/1000 [13:50:28<87:39:13, 363.12s/it] 13%|â–ˆâ–Ž        | 132/1000 [13:56:14<86:17:00, 357.86s/it] 13%|â–ˆâ–Ž        | 133/1000 [14:02:00<85:19:00, 354.26s/it] 13%|â–ˆâ–Ž        | 134/1000 [14:07:45<84:36:16, 351.70s/it] 14%|â–ˆâ–Ž        | 135/1000 [14:13:31<84:04:17, 349.89s/it] 14%|â–ˆâ–Ž        | 136/1000 [14:19:17<83:40:24, 348.64s/it] 14%|â–ˆâ–Ž        | 137/1000 [14:25:03<83:22:16, 347.78s/it] 14%|â–ˆâ–        | 138/1000 [14:30:49<83:08:57, 347.26s/it] 14%|â–ˆâ–        | 139/1000 [14:36:34<82:56:26, 346.79s/it] 14%|â–ˆâ–        | 139/1000 [14:42:20<91:05:28, 380.87s/it]
Epoch: 80/1000. Validation set: Average loss: -2.2791
Epoch: 81/1000. Train set: Average loss: -2.2790
Epoch: 81/1000. Validation set: Average loss: -2.2791
Epoch: 82/1000. Train set: Average loss: -2.2788
Epoch: 82/1000. Validation set: Average loss: -2.2789
Epoch: 83/1000. Train set: Average loss: -2.2788
Epoch: 83/1000. Validation set: Average loss: -2.2785
Epoch: 84/1000. Train set: Average loss: -2.2792
Epoch: 84/1000. Validation set: Average loss: -2.2793
Epoch: 85/1000. Train set: Average loss: -2.2790
Epoch: 85/1000. Validation set: Average loss: -2.2786
Epoch: 86/1000. Train set: Average loss: -2.2792
Epoch: 86/1000. Validation set: Average loss: -2.2793
Epoch: 87/1000. Train set: Average loss: -2.2787
Epoch: 87/1000. Validation set: Average loss: -2.2793
Epoch: 88/1000. Train set: Average loss: -2.2793
Epoch: 88/1000. Validation set: Average loss: -2.2791
Epoch: 89/1000. Train set: Average loss: -2.2793
Epoch: 89/1000. Validation set: Average loss: -2.2788
Epoch: 90/1000. Train set: Average loss: -2.2792
Epoch: 90/1000. Validation set: Average loss: -2.2790
Epoch: 91/1000. Train set: Average loss: -2.2789
Epoch: 91/1000. Validation set: Average loss: -2.2787
Epoch: 92/1000. Train set: Average loss: -2.2793
Epoch: 92/1000. Validation set: Average loss: -2.2793
Epoch: 93/1000. Train set: Average loss: -2.2792
Epoch: 93/1000. Validation set: Average loss: -2.2791
Epoch: 94/1000. Train set: Average loss: -2.2792
Epoch: 94/1000. Validation set: Average loss: -2.2792
Epoch: 95/1000. Train set: Average loss: -2.2792
Epoch: 95/1000. Validation set: Average loss: -2.2786
Epoch: 96/1000. Train set: Average loss: -2.2794
Epoch: 96/1000. Validation set: Average loss: -2.2786
Epoch: 97/1000. Train set: Average loss: -2.2790
Epoch: 97/1000. Validation set: Average loss: -2.2789
Epoch: 98/1000. Train set: Average loss: -2.2795
Epoch: 98/1000. Validation set: Average loss: -2.2790
Epoch: 99/1000. Train set: Average loss: -2.2792
Epoch: 99/1000. Validation set: Average loss: -2.2793
Epoch: 100/1000. Train set: Average loss: -2.2795
Epoch: 100/1000. Validation set: Average loss: -2.2793
Epoch: 101/1000. Train set: Average loss: -2.2794
Epoch: 101/1000. Validation set: Average loss: -2.2792
Epoch: 102/1000. Train set: Average loss: -2.2793
Epoch: 102/1000. Validation set: Average loss: -2.2789
Epoch: 103/1000. Train set: Average loss: -2.2793
Epoch: 103/1000. Validation set: Average loss: -2.2778
Epoch: 104/1000. Train set: Average loss: -2.2791
Epoch: 104/1000. Validation set: Average loss: -2.2791
Epoch: 105/1000. Train set: Average loss: -2.2794
Epoch: 105/1000. Validation set: Average loss: -2.2793
Epoch: 106/1000. Train set: Average loss: -2.2792
Epoch: 106/1000. Validation set: Average loss: -2.2788
Epoch: 107/1000. Train set: Average loss: -2.2793
Epoch: 107/1000. Validation set: Average loss: -2.2791
Epoch: 108/1000. Train set: Average loss: -2.2791
Epoch: 108/1000. Validation set: Average loss: -2.2793
Epoch: 109/1000. Train set: Average loss: -2.2790
Epoch: 109/1000. Validation set: Average loss: -2.2787
Epoch: 110/1000. Train set: Average loss: -2.2792
Epoch: 110/1000. Validation set: Average loss: -2.2787
Epoch: 111/1000. Train set: Average loss: -2.2795
Epoch: 111/1000. Validation set: Average loss: -2.2788
Epoch: 112/1000. Train set: Average loss: -2.2795
Epoch: 112/1000. Validation set: Average loss: -2.2793
Epoch: 113/1000. Train set: Average loss: -2.2794
Epoch: 113/1000. Validation set: Average loss: -2.2793
Epoch: 114/1000. Train set: Average loss: -2.2795
Epoch: 114/1000. Validation set: Average loss: -2.2793
Epoch: 115/1000. Train set: Average loss: -2.2793
Epoch: 115/1000. Validation set: Average loss: -2.2793
Epoch: 116/1000. Train set: Average loss: -2.2794
Epoch: 116/1000. Validation set: Average loss: -2.2793
Epoch: 117/1000. Train set: Average loss: -2.2795
Epoch: 117/1000. Validation set: Average loss: -2.2793
Epoch: 118/1000. Train set: Average loss: -2.2795
Epoch: 118/1000. Validation set: Average loss: -2.2793
Epoch: 119/1000. Train set: Average loss: -2.2795
Epoch: 119/1000. Validation set: Average loss: -2.2793
Epoch: 120/1000. Train set: Average loss: -2.2795
Epoch: 120/1000. Validation set: Average loss: -2.2793
Epoch: 121/1000. Train set: Average loss: -2.2793
Epoch: 121/1000. Validation set: Average loss: -2.2792
Epoch: 122/1000. Train set: Average loss: -2.2795
Epoch: 122/1000. Validation set: Average loss: -2.2791
Epoch: 123/1000. Train set: Average loss: -2.2795
Epoch: 123/1000. Validation set: Average loss: -2.2793
Epoch: 124/1000. Train set: Average loss: -2.2796
Epoch: 124/1000. Validation set: Average loss: -2.2793
Epoch: 125/1000. Train set: Average loss: -2.2795
Epoch: 125/1000. Validation set: Average loss: -2.2790
Epoch: 126/1000. Train set: Average loss: -2.2795
Epoch: 126/1000. Validation set: Average loss: -2.2793
Epoch: 127/1000. Train set: Average loss: -2.2795
Epoch: 127/1000. Validation set: Average loss: -2.2793
Epoch: 128/1000. Train set: Average loss: -2.2796
Epoch: 128/1000. Validation set: Average loss: -2.2793
Epoch: 129/1000. Train set: Average loss: -2.2795
Epoch: 129/1000. Validation set: Average loss: -2.2793
Epoch: 130/1000. Train set: Average loss: -2.2795
Epoch: 130/1000. Validation set: Average loss: -2.2792
Epoch: 131/1000. Train set: Average loss: -2.2795
Epoch: 131/1000. Validation set: Average loss: -2.2788
Epoch: 132/1000. Train set: Average loss: -2.2793
Epoch: 132/1000. Validation set: Average loss: -2.2793
Epoch: 133/1000. Train set: Average loss: -2.2795
Epoch: 133/1000. Validation set: Average loss: -2.2793
Epoch: 134/1000. Train set: Average loss: -2.2795
Epoch: 134/1000. Validation set: Average loss: -2.2793
Epoch: 135/1000. Train set: Average loss: -2.2795
Epoch: 135/1000. Validation set: Average loss: -2.2793
Epoch: 136/1000. Train set: Average loss: -2.2795
Epoch: 136/1000. Validation set: Average loss: -2.2793
Epoch: 137/1000. Train set: Average loss: -2.2795
Epoch: 137/1000. Validation set: Average loss: -2.2793
Epoch: 138/1000. Train set: Average loss: -2.2794
Epoch: 138/1000. Validation set: Average loss: -2.2793
Epoch: 139/1000. Train set: Average loss: -2.2795
Epoch: 139/1000. Validation set: Average loss: -2.2793
Epoch: 140/1000. Train set: Average loss: -2.2795
Epoch: 140/1000. Validation set: Average loss: -2.2790
yo?
Training time: 52976.05 seconds
Initial Window: tensor([[-6.6552,  0.5743, -2.0714,  4.9840,  8.8309, -1.0462,  4.6527, 10.7432],
        [-1.2573,  7.1192, 11.5621,  6.1425,  4.6180,  2.1320,  6.4135,  6.0790],
        [ 2.6308,  9.7157, 10.4960, -4.0719,  4.2621,  7.6632,  8.4280,  2.7578],
        [ 3.5314, 11.6621, -4.1574, -0.8401, -0.3725, 13.6223,  2.9777, -2.3032],
        [ 5.1709, 10.8603,  1.5052,  5.3575, 10.2030,  5.3154, -5.2997,  2.4698],
        [10.5231,  9.8095, -0.6279,  6.6502,  6.5805, -5.7486,  2.8205,  3.1672],
        [ 5.0987, -6.5853,  0.9564,  8.1044,  2.5500, -3.7802,  1.2906, 13.2256],
        [-0.7764,  0.9630, -1.0545,  8.2193,  2.7532, -1.9499, -0.7012, 13.0293],
        [ 4.3098, -1.4679,  3.2837,  9.0329, -0.0238, -0.2983,  0.3141, 12.5709],
        [-3.2271,  1.6273,  3.9535, 10.1696,  0.9897,  3.0876,  6.8140, 10.1955]])
Next 10 (9 prediction_length) steps tensor([[-3.2271,  1.6273,  3.9535, 10.1696,  0.9897,  3.0876,  6.8140, 10.1955],
        [-2.4412,  1.4171, 11.8924,  5.5080, -2.5457,  4.1696, 10.3193, -1.5410],
        [ 4.4459,  8.1026,  9.1760, -3.9613,  0.8670,  3.4818, 10.2734, -0.1379],
        [ 5.9674,  8.7886, -4.9083, -0.0667,  0.8987,  9.6319,  9.1128, -0.1576],
        [ 6.9344,  4.8333, -3.8852,  3.3546, 11.8590,  8.3064, -3.2138,  0.3050],
        [ 8.4130,  2.1772, -2.3242,  0.2615, 13.1742, -2.2076,  0.1661, -0.2565],
        [ 8.4880, -1.0374,  0.9322,  1.5652, 12.9802,  4.5080,  0.3643,  4.7071],
        [ 7.4834, -0.7099,  4.0739, 10.1310,  8.0202, -4.6900,  2.4052,  7.3596],
        [ 4.5218, -1.9389,  4.2597, 10.7186, -4.9986,  2.3751,  1.0690, 10.4754],
        [-3.4356,  0.8486,  5.4150, 10.1238,  1.6039,  6.4489, 11.1378,  0.3445]])
predicted output from the model tensor([[[-259940.1250, -178434.7656,  772017.8125, 1116304.6250, 1108771.5000,
          2771473.5000, 1721061.0000, 1424644.5000],
         [-250529.7344, -171971.8594,  744055.9375, 1075876.0000, 1068617.3750,
          2671117.7500, 1658735.8750, 1373051.1250],
         [-231714.0000, -159049.4375,  688147.0000,  995039.7500,  988330.4375,
          2470460.0000, 1534118.7500, 1269891.5000],
         [-242341.2031, -166348.0625,  719724.5625, 1040696.3125, 1033676.7500,
          2583792.5000, 1604502.8750, 1328156.2500],
         [-255499.7969, -175385.2031,  758824.0625, 1097228.3750, 1089824.8750,
          2724121.0000, 1691653.0000, 1400300.0000],
         [-246423.6250, -169151.8281,  731855.0000, 1058235.2500, 1051096.5000,
          2627329.0000, 1631541.1250, 1350538.6250],
         [-239721.6250, -164548.9375,  711940.6875, 1029442.0000, 1022498.8125,
          2555856.0000, 1587153.2500, 1313794.2500],
         [-239991.6094, -164734.3750,  712742.9375, 1030602.1250, 1023651.1250,
          2558735.7500, 1588941.5000, 1315274.3750],
         [-258669.1562, -177561.8750,  768241.3125, 1110844.5000, 1103348.5000,
          2757919.7500, 1712643.5000, 1417676.3750],
         [-266663.7812, -183048.2812,  791976.8750, 1145166.8750, 1137441.1250,
          2843144.5000, 1765564.1250, 1461480.5000]],

        [[-257183.7031, -176541.7031,  763827.5000, 1104462.7500, 1097010.0000,
          2742078.2500, 1702805.2500, 1409532.1250],
         [-247933.7656, -170188.9531,  736342.3125, 1064723.0000, 1057540.3750,
          2643433.7500, 1641542.6250, 1358818.2500],
         [-247267.2188, -169731.1875,  734361.6250, 1061859.3750, 1054696.1250,
          2636325.0000, 1637128.2500, 1355163.7500],
         [-259765.0000, -178314.5312,  771497.5000, 1115552.6250, 1108024.5000,
          2769606.7500, 1719901.6250, 1423684.7500],
         [-262894.8438, -180464.0469,  780797.5000, 1128999.0000, 1121379.6250,
          2802984.5000, 1740630.5000, 1440844.1250],
         [-233882.9688, -160539.0625,  694591.8750, 1004358.1875,  997585.3125,
          2493591.0000, 1548483.8750, 1281782.8750],
         [-236326.5000, -162217.2031,  701852.3750, 1014856.0000, 1008011.8125,
          2519649.2500, 1564667.2500, 1295179.8750],
         [-259991.3906, -178470.0312,  772170.3125, 1116525.0000, 1108990.3750,
          2772021.0000, 1721400.8750, 1424925.7500],
         [-233829.7031, -160502.4219,  694433.5000, 1004129.0000,  997358.0000,
          2493022.5000, 1548130.8750, 1281491.0000],
         [-257937.0000, -177054.7812,  766046.1875, 1107674.8750, 1100203.6250,
          2750079.0000, 1707766.2500, 1413634.7500]],

        [[-252123.3125, -173066.2812,  748791.0000, 1082722.1250, 1075417.1250,
          2688112.7500, 1669290.1250, 1381788.0000],
         [-294038.2188, -201853.0469,  873337.0625, 1262797.3750, 1254269.3750,
          3135110.2500, 1946894.6250, 1611592.6250],
         [-241413.9688, -165711.2031,  716969.3750, 1036712.8125, 1029720.2500,
          2573904.2500, 1598361.7500, 1323072.7500],
         [-243550.5000, -167178.5469,  723317.8125, 1045891.7500, 1038836.8750,
          2596689.0000, 1612512.0000, 1334786.3750],
         [-243211.7031, -166945.9062,  722311.0625, 1044436.1875, 1037391.3125,
          2593076.0000, 1610268.3750, 1332928.8750],
         [-256382.6250, -175991.5938,  761447.2500, 1101021.3750, 1093591.8750,
          2733535.7500, 1697500.1250, 1405140.5000],
         [-265823.4688, -182475.3906,  789499.8125, 1141581.0000, 1133876.2500,
          2834217.0000, 1760027.1250, 1456901.2500],
         [-237295.9375, -162883.0156,  704732.9375, 1019020.8125, 1012148.5000,
          2529987.7500, 1571087.8750, 1300495.1250],
         [-246654.2031, -169310.1562,  732540.1875, 1059225.7500, 1052080.3750,
          2629787.7500, 1633068.0000, 1351802.8750],
         [-246483.6719, -169188.7969,  732013.6875, 1058468.8750, 1051332.0000,
          2627935.7500, 1631910.3750, 1350840.5000]]], device='cuda:0',
       grad_fn=<CatBackward0>) torch.Size([3, 10, 8])
-2.2795390876321684
