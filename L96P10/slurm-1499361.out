/scrtp/avon/eb/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Train SR network for lorenz96 model with lr 0.0003 using SignatureKernel scoring rule
  0%|          | 0/1000 [00:00<?, ?it/s]/gpfs/home/stats/stubxk/ArcherDissEnv3/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: [1mGrid size 9 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
/gpfs/home/stats/stubxk/ArcherDissEnv3/lib/python3.11/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: [1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.[0m
  warn(NumbaPerformanceWarning(msg))
  0%|          | 1/1000 [05:49<97:00:59, 349.61s/it]  0%|          | 2/1000 [11:37<96:42:28, 348.85s/it]  0%|          | 3/1000 [17:23<96:10:02, 347.24s/it]  0%|          | 4/1000 [23:08<95:48:15, 346.28s/it]  0%|          | 5/1000 [28:50<95:17:21, 344.77s/it]  1%|          | 6/1000 [34:29<94:40:06, 342.86s/it]  1%|          | 7/1000 [40:05<93:59:06, 340.73s/it]  1%|          | 8/1000 [45:42<93:35:29, 339.65s/it]  1%|          | 9/1000 [51:22<93:27:04, 339.48s/it]  1%|          | 10/1000 [57:01<93:19:47, 339.38s/it]  1%|          | 11/1000 [1:02:40<93:13:12, 339.33s/it]  1%|          | 12/1000 [1:08:19<93:08:00, 339.35s/it]  1%|â–         | 13/1000 [1:13:59<93:02:50, 339.38s/it]  1%|â–         | 14/1000 [1:19:38<92:56:27, 339.34s/it]  2%|â–         | 15/1000 [1:25:17<92:49:15, 339.24s/it]  2%|â–         | 16/1000 [1:30:56<92:42:31, 339.18s/it]  2%|â–         | 17/1000 [1:36:35<92:36:28, 339.15s/it]  2%|â–         | 18/1000 [1:42:15<92:31:40, 339.21s/it]  2%|â–         | 19/1000 [1:47:54<92:25:43, 339.19s/it]  2%|â–         | 20/1000 [1:53:31<92:10:38, 338.61s/it]  2%|â–         | 21/1000 [1:59:08<91:59:05, 338.25s/it]  2%|â–         | 22/1000 [2:04:46<91:49:24, 338.00s/it]  2%|â–         | 23/1000 [2:10:23<91:41:11, 337.84s/it]  2%|â–         | 24/1000 [2:16:01<91:33:46, 337.73s/it]  2%|â–Ž         | 25/1000 [2:21:38<91:25:39, 337.58s/it]  3%|â–Ž         | 26/1000 [2:27:15<91:19:21, 337.54s/it]  3%|â–Ž         | 27/1000 [2:32:53<91:13:04, 337.50s/it]  3%|â–Ž         | 28/1000 [2:38:30<91:07:42, 337.51s/it]  3%|â–Ž         | 29/1000 [2:44:08<91:01:03, 337.45s/it]  3%|â–Ž         | 30/1000 [2:49:45<90:55:29, 337.45s/it]  3%|â–Ž         | 31/1000 [2:55:22<90:47:56, 337.33s/it]  3%|â–Ž         | 32/1000 [3:00:59<90:41:44, 337.30s/it]  3%|â–Ž         | 33/1000 [3:06:36<90:31:33, 337.01s/it]  3%|â–Ž         | 34/1000 [3:12:13<90:25:08, 336.97s/it]  4%|â–Ž         | 35/1000 [3:17:49<90:18:24, 336.90s/it]  4%|â–Ž         | 36/1000 [3:23:25<90:06:23, 336.50s/it]  4%|â–Ž         | 37/1000 [3:29:01<89:57:33, 336.30s/it]  4%|â–         | 38/1000 [3:34:37<89:51:04, 336.24s/it]  4%|â–         | 39/1000 [3:40:12<89:42:40, 336.07s/it]  4%|â–         | 40/1000 [3:45:48<89:35:44, 335.98s/it]  4%|â–         | 41/1000 [3:51:24<89:29:18, 335.93s/it]  4%|â–         | 42/1000 [3:57:00<89:24:01, 335.95s/it]  4%|â–         | 43/1000 [4:02:36<89:20:43, 336.10s/it]  4%|â–         | 44/1000 [4:08:13<89:15:18, 336.11s/it]  4%|â–         | 45/1000 [4:13:49<89:09:04, 336.07s/it]  5%|â–         | 46/1000 [4:19:25<89:03:32, 336.07s/it]  5%|â–         | 47/1000 [4:25:01<88:57:47, 336.06s/it]  5%|â–         | 48/1000 [4:30:37<88:54:02, 336.18s/it]  5%|â–         | 49/1000 [4:36:13<88:48:37, 336.19s/it]  5%|â–Œ         | 50/1000 [4:41:49<88:42:17, 336.14s/it]  5%|â–Œ         | 51/1000 [4:47:26<88:36:39, 336.14s/it]  5%|â–Œ         | 52/1000 [4:53:02<88:31:30, 336.17s/it]  5%|â–Œ         | 53/1000 [4:58:38<88:26:35, 336.21s/it]  5%|â–Œ         | 54/1000 [5:04:14<88:20:28, 336.18s/it]  6%|â–Œ         | 55/1000 [5:09:52<88:23:45, 336.75s/it]  6%|â–Œ         | 56/1000 [5:15:31<88:29:00, 337.44s/it]  6%|â–Œ         | 57/1000 [5:21:10<88:30:47, 337.91s/it]  6%|â–Œ         | 58/1000 [5:26:46<88:16:36, 337.36s/it]  6%|â–Œ         | 59/1000 [5:32:23<88:05:38, 337.02s/it]  6%|â–Œ         | 60/1000 [5:37:59<87:56:42, 336.81s/it]  6%|â–Œ         | 61/1000 [5:43:34<87:44:52, 336.41s/it]  6%|â–Œ         | 62/1000 [5:49:10<87:35:41, 336.18s/it]  6%|â–‹         | 63/1000 [5:54:46<87:28:58, 336.11s/it]  6%|â–‹         | 64/1000 [6:00:22<87:21:35, 336.00s/it]  6%|â–‹         | 65/1000 [6:05:58<87:16:13, 336.01s/it]  7%|â–‹         | 66/1000 [6:11:34<87:09:58, 335.97s/it]  7%|â–‹         | 67/1000 [6:17:09<87:03:13, 335.90s/it]  7%|â–‹         | 68/1000 [6:22:46<86:58:27, 335.95s/it]  7%|â–‹         | 69/1000 [6:28:21<86:51:49, 335.89s/it]  7%|â–‹         | 70/1000 [6:33:57<86:46:19, 335.89s/it]  7%|â–‹         | 71/1000 [6:39:33<86:40:28, 335.88s/it]  7%|â–‹         | 72/1000 [6:Epoch: 1/1000. Train set: Average loss: 2.6750
Epoch: 1/1000. Validation set: Average loss: 2.6447
Epoch: 2/1000. Train set: Average loss: 2.6726
Epoch: 2/1000. Validation set: Average loss: 2.6411
Epoch: 3/1000. Train set: Average loss: 2.6698
Epoch: 3/1000. Validation set: Average loss: 2.6366
Epoch: 4/1000. Train set: Average loss: 2.6659
Epoch: 4/1000. Validation set: Average loss: 2.6300
Epoch: 5/1000. Train set: Average loss: 2.6592
Epoch: 5/1000. Validation set: Average loss: 2.6175
Epoch: 6/1000. Train set: Average loss: 2.6431
Epoch: 6/1000. Validation set: Average loss: 2.5870
Epoch: 7/1000. Train set: Average loss: 2.5935
Epoch: 7/1000. Validation set: Average loss: 2.4885
Epoch: 8/1000. Train set: Average loss: 2.4221
Epoch: 8/1000. Validation set: Average loss: 2.1578
Epoch: 9/1000. Train set: Average loss: 1.9550
Epoch: 9/1000. Validation set: Average loss: 1.4103
Epoch: 10/1000. Train set: Average loss: 1.0168
Epoch: 10/1000. Validation set: Average loss: 0.1983
Epoch: 11/1000. Train set: Average loss: -0.1539
Epoch: 11/1000. Validation set: Average loss: -0.5020
Epoch: 12/1000. Train set: Average loss: -0.5822
Epoch: 12/1000. Validation set: Average loss: -0.6073
Epoch: 13/1000. Train set: Average loss: -0.6222
Epoch: 13/1000. Validation set: Average loss: -0.6040
Epoch: 14/1000. Train set: Average loss: -0.6201
Epoch: 14/1000. Validation set: Average loss: -0.6097
Epoch: 15/1000. Train set: Average loss: -0.6268
Epoch: 15/1000. Validation set: Average loss: -0.6129
Epoch: 16/1000. Train set: Average loss: -0.6303
Epoch: 16/1000. Validation set: Average loss: -0.6166
Epoch: 17/1000. Train set: Average loss: -0.6314
Epoch: 17/1000. Validation set: Average loss: -0.6173
Epoch: 18/1000. Train set: Average loss: -0.6344
Epoch: 18/1000. Validation set: Average loss: -0.6172
Epoch: 19/1000. Train set: Average loss: -0.6368
Epoch: 19/1000. Validation set: Average loss: -0.6199
Epoch: 20/1000. Train set: Average loss: -0.6377
Epoch: 20/1000. Validation set: Average loss: -0.6218
Epoch: 21/1000. Train set: Average loss: -0.6445
Epoch: 21/1000. Validation set: Average loss: -0.6256
Epoch: 22/1000. Train set: Average loss: -0.6452
Epoch: 22/1000. Validation set: Average loss: -0.6344
Epoch: 23/1000. Train set: Average loss: -0.6492
Epoch: 23/1000. Validation set: Average loss: -0.6373
Epoch: 24/1000. Train set: Average loss: -0.6581
Epoch: 24/1000. Validation set: Average loss: -0.6492
Epoch: 25/1000. Train set: Average loss: -0.6655
Epoch: 25/1000. Validation set: Average loss: -0.6543
Epoch: 26/1000. Train set: Average loss: -0.6748
Epoch: 26/1000. Validation set: Average loss: -0.6655
Epoch: 27/1000. Train set: Average loss: -0.6954
Epoch: 27/1000. Validation set: Average loss: -0.6950
Epoch: 28/1000. Train set: Average loss: -0.7169
Epoch: 28/1000. Validation set: Average loss: -0.7225
Epoch: 29/1000. Train set: Average loss: -0.7615
Epoch: 29/1000. Validation set: Average loss: -0.7764
Epoch: 30/1000. Train set: Average loss: -0.8386
Epoch: 30/1000. Validation set: Average loss: -0.8595
Epoch: 31/1000. Train set: Average loss: -0.9143
Epoch: 31/1000. Validation set: Average loss: -0.9578
Epoch: 32/1000. Train set: Average loss: -1.0032
Epoch: 32/1000. Validation set: Average loss: -1.0633
Epoch: 33/1000. Train set: Average loss: -1.0712
Epoch: 33/1000. Validation set: Average loss: -0.9485
Epoch: 34/1000. Train set: Average loss: -1.1081
Epoch: 34/1000. Validation set: Average loss: -1.1212
Epoch: 35/1000. Train set: Average loss: -1.1433
Epoch: 35/1000. Validation set: Average loss: -1.1250
Epoch: 36/1000. Train set: Average loss: -1.1621
Epoch: 36/1000. Validation set: Average loss: -1.1670
Epoch: 37/1000. Train set: Average loss: -1.1699
Epoch: 37/1000. Validation set: Average loss: -1.1886
Epoch: 38/1000. Train set: Average loss: -1.2007
Epoch: 38/1000. Validation set: Average loss: -1.1791
Epoch: 39/1000. Train set: Average loss: -1.2169
Epoch: 39/1000. Validation set: Average loss: -1.2124
Epoch: 40/1000. Train set: Average loss: -1.2022
Epoch: 40/1000. Validation set: Average loss: -1.2069
Epoch: 41/1000. Train set: Average loss: -1.2207
Epoch: 41/1000. Validation set: Average loss: -1.2265
Epoch: 42/1000. Train set: Average loss: -1.2401
Epoch: 42/1000. Validation set: Average loss: -1.2017
Epoch: 43/1000. Train set: Average loss: -1.2542
Epoch: 43/1000. Validation set: Average loss: -1.2623
Epoch: 44/1000. Train set: Average loss: -1.2411
Epoch: 44/1000. Validation set: Average loss: -1.2334
Epoch: 45/1000. Train set: Average loss: -1.2386
Epoch: 45/1000. Validation set: Average loss: -1.2307
Epoch: 46/1000. Train set: Average loss: -1.2751
Epoch: 46/1000. Validation set: Average loss: -1.2695
Epoch: 47/1000. Train set: Average loss: -1.2849
Epoch: 47/1000. Validation set: Average loss: -1.2774
Epoch: 48/1000. Train set: Average loss: -1.2915
Epoch: 48/1000. Validation set: Average loss: -1.3039
Epoch: 49/1000. Train set: Average loss: -1.3001
Epoch: 49/1000. Validation set: Average loss: -1.3049
Epoch: 50/1000. Train set: Average loss: -1.3062
Epoch: 50/1000. Validation set: Average loss: -1.2974
Epoch: 51/1000. Train set: Average loss: -1.3166
Epoch: 51/1000. Validation set: Average loss: -1.3134
Epoch: 52/1000. Train set: Average loss: -1.3333
Epoch: 52/1000. Validation set: Average loss: -1.3165
Epoch: 53/1000. Train set: Average loss: -1.3474
Epoch: 53/1000. Validation set: Average loss: -1.3240
Epoch: 54/1000. Train set: Average loss: -1.3254
Epoch: 54/1000. Validation set: Average loss: -1.3562
Epoch: 55/1000. Train set: Average loss: -1.3476
Epoch: 55/1000. Validation set: Average loss: -1.3548
Epoch: 56/1000. Train set: Average loss: -1.3774
Epoch: 56/1000. Validation set: Average loss: -1.3643
Epoch: 57/1000. Train set: Average loss: -1.3775
Epoch: 57/1000. Validation set: Average loss: -1.3895
Epoch: 58/1000. Train set: Average loss: -1.3895
Epoch: 58/1000. Validation set: Average loss: -1.3823
Epoch: 59/1000. Train set: Average loss: -1.4058
Epoch: 59/1000. Validation set: Average loss: -1.4397
Epoch: 60/1000. Train set: Average loss: -1.4303
Epoch: 60/1000. Validation set: Average loss: -1.4080
Epoch: 61/1000. Train set: Average loss: -1.4473
Epoch: 61/1000. Validation set: Average loss: -1.4722
Epoch: 62/1000. Train set: Average loss: -1.4849
Epoch: 62/1000. Validation set: Average loss: -1.4181
Epoch: 63/1000. Train set: Average loss: -1.4625
Epoch: 63/1000. Validation set: Average loss: -1.4980
Epoch: 64/1000. Train set: Average loss: -1.4861
Epoch: 64/1000. Validation set: Average loss: -1.5135
Epoch: 65/1000. Train set: Average loss: -1.5166
Epoch: 65/1000. Validation set: Average loss: -1.5020
Epoch: 66/1000. Train set: Average loss: -1.5324
Epoch: 66/1000. Validation set: Average loss: -1.5566
Epoch: 67/1000. Train set: Average loss: -1.5475
Epoch: 67/1000. Validation set: Average loss: -1.5474
Epoch: 68/1000. Train set: Average loss: -1.5871
Epoch: 68/1000. Validation set: Average loss: -1.5721
Epoch: 69/1000. Train set: Average loss: -1.5898
Epoch: 69/1000. Validation set: Average loss: -1.5834
Epoch: 70/1000. Train set: Average loss: -1.5826
Epoch: 70/1000. Validation set: Average loss: -1.5998
Epoch: 71/1000. Train set: Average loss: -1.5845
Epoch: 71/1000. Validation set: Average loss: -1.5566
Epoch: 72/1000. Train set: Average loss: -1.6132
Epoch: 72/1000. Validation set: Average loss: -1.6399
Epoch: 73/1000. Train set: Average loss: -1.6239
Epoch: 73/1000. Validation set: Average loss: -1.6379
Epoch: 74/1000. Train set: Average loss: -1.6433
Epoch: 74/1000. Validation set: Average loss: -1.6475
Epoch: 75/1000. Train set: Average loss: -1.6448
Epoch: 75/1000. Validation set: Average loss: -1.6463
Epoch: 76/1000. Train set: Average loss: -1.6403
Epoch: 76/1000. Validation set: Average loss: -1.6632
Epoch: 77/1000. Train set: Average loss: -1.6862
Epoch: 77/1000. Validation set: Average loss: -1.6077
Epoch: 78/1000. Train set: Average loss: -1.6762
Epoch: 78/1000. Validation set: Average loss: -1.6988
Epoch: 79/1000. Train set: Average loss: -1.6965
Epoch: 79/1000. Validation set: Average loss: -1.7062
Epoch: 80/1000. Train set: Average loss: -1.7140
45:09<86:34:13, 335.83s/it]  7%|â–‹         | 73/1000 [6:50:45<86:28:58, 335.86s/it]  7%|â–‹         | 74/1000 [6:56:21<86:23:27, 335.86s/it]  8%|â–Š         | 75/1000 [7:01:56<86:17:24, 335.83s/it]  8%|â–Š         | 76/1000 [7:07:32<86:12:10, 335.86s/it]  8%|â–Š         | 77/1000 [7:13:08<86:06:07, 335.83s/it]  8%|â–Š         | 78/1000 [7:18:44<86:01:23, 335.88s/it]  8%|â–Š         | 79/1000 [7:24:20<85:54:43, 335.81s/it]  8%|â–Š         | 80/1000 [7:29:55<85:48:21, 335.76s/it]  8%|â–Š         | 81/1000 [7:35:31<85:42:24, 335.74s/it]  8%|â–Š         | 82/1000 [7:41:07<85:37:25, 335.78s/it]  8%|â–Š         | 83/1000 [7:46:43<85:32:18, 335.81s/it]  8%|â–Š         | 84/1000 [7:52:19<85:26:56, 335.83s/it]  8%|â–Š         | 85/1000 [7:57:55<85:22:17, 335.89s/it]  9%|â–Š         | 86/1000 [8:03:31<85:16:54, 335.90s/it]  9%|â–Š         | 87/1000 [8:09:06<85:11:18, 335.90s/it]  9%|â–‰         | 88/1000 [8:14:42<85:05:51, 335.91s/it]  9%|â–‰         | 89/1000 [8:20:18<84:59:16, 335.85s/it]  9%|â–‰         | 90/1000 [8:25:54<84:53:17, 335.82s/it]  9%|â–‰         | 91/1000 [8:31:29<84:46:54, 335.77s/it]  9%|â–‰         | 92/1000 [8:37:05<84:41:35, 335.79s/it]  9%|â–‰         | 93/1000 [8:42:41<84:36:45, 335.84s/it]  9%|â–‰         | 94/1000 [8:48:17<84:30:20, 335.78s/it] 10%|â–‰         | 95/1000 [8:53:53<84:25:34, 335.84s/it] 10%|â–‰         | 96/1000 [8:59:27<84:14:15, 335.46s/it] 10%|â–‰         | 97/1000 [9:05:02<84:03:32, 335.12s/it] 10%|â–‰         | 98/1000 [9:10:36<83:55:24, 334.95s/it] 10%|â–‰         | 99/1000 [9:16:11<83:47:03, 334.77s/it] 10%|â–ˆ         | 100/1000 [9:21:45<83:39:25, 334.63s/it] 10%|â–ˆ         | 101/1000 [9:27:19<83:32:11, 334.52s/it] 10%|â–ˆ         | 102/1000 [9:32:54<83:26:10, 334.49s/it] 10%|â–ˆ         | 103/1000 [9:38:28<83:20:30, 334.48s/it] 10%|â–ˆ         | 104/1000 [9:44:03<83:14:40, 334.46s/it] 10%|â–ˆ         | 105/1000 [9:49:37<83:09:03, 334.46s/it] 11%|â–ˆ         | 106/1000 [9:55:11<83:02:43, 334.41s/it] 11%|â–ˆ         | 107/1000 [10:00:46<82:56:34, 334.37s/it] 11%|â–ˆ         | 108/1000 [10:06:20<82:52:30, 334.47s/it] 11%|â–ˆ         | 109/1000 [10:11:55<82:46:23, 334.44s/it] 11%|â–ˆ         | 110/1000 [10:17:29<82:40:10, 334.39s/it] 11%|â–ˆ         | 111/1000 [10:23:03<82:34:01, 334.35s/it] 11%|â–ˆ         | 112/1000 [10:28:38<82:29:26, 334.42s/it] 11%|â–ˆâ–        | 113/1000 [10:34:12<82:23:53, 334.42s/it] 11%|â–ˆâ–        | 114/1000 [10:39:47<82:17:59, 334.40s/it] 12%|â–ˆâ–        | 115/1000 [10:45:21<82:11:43, 334.35s/it] 12%|â–ˆâ–        | 116/1000 [10:50:57<82:13:12, 334.83s/it] 12%|â–ˆâ–        | 117/1000 [10:56:34<82:19:56, 335.67s/it] 12%|â–ˆâ–        | 118/1000 [11:02:13<82:27:08, 336.54s/it] 12%|â–ˆâ–        | 119/1000 [11:07:51<82:29:45, 337.10s/it] 12%|â–ˆâ–        | 120/1000 [11:13:30<82:30:34, 337.54s/it] 12%|â–ˆâ–        | 121/1000 [11:19:08<82:28:56, 337.81s/it] 12%|â–ˆâ–        | 122/1000 [11:24:47<82:27:48, 338.12s/it] 12%|â–ˆâ–        | 123/1000 [11:30:26<82:24:37, 338.29s/it] 12%|â–ˆâ–        | 124/1000 [11:36:04<82:19:59, 338.36s/it] 12%|â–ˆâ–Ž        | 125/1000 [11:41:43<82:15:46, 338.45s/it] 13%|â–ˆâ–Ž        | 126/1000 [11:47:22<82:10:43, 338.49s/it] 13%|â–ˆâ–Ž        | 127/1000 [11:53:00<82:05:32, 338.52s/it] 13%|â–ˆâ–Ž        | 128/1000 [11:58:39<82:00:40, 338.58s/it] 13%|â–ˆâ–Ž        | 129/1000 [12:04:18<81:55:57, 338.64s/it] 13%|â–ˆâ–Ž        | 130/1000 [12:09:57<81:51:03, 338.69s/it] 13%|â–ˆâ–Ž        | 131/1000 [12:15:35<81:45:05, 338.67s/it] 13%|â–ˆâ–Ž        | 132/1000 [12:21:14<81:39:47, 338.70s/it] 13%|â–ˆâ–Ž        | 133/1000 [12:26:53<81:34:43, 338.74s/it] 13%|â–ˆâ–Ž        | 134/1000 [12:32:32<81:30:33, 338.84s/it] 14%|â–ˆâ–Ž        | 135/1000 [12:38:11<81:24:18, 338.80s/it] 14%|â–ˆâ–Ž        | 136/1000 [12:43:49<81:18:40, 338.80s/it] 14%|â–ˆâ–Ž        | 137/1000 [12:49:28<81:13:15, 338.81s/it] 14%|â–ˆâ–        | 138/1000 [12:55:07<81:08:24, 338.87s/it] 14%|â–ˆâ–        | 139/1000 [13:00:46<81:02:05, 338.82s/it] 14%|â–ˆâ–        | 139/1000 [13:06:25<81:11:17, 339.46s/it]
Epoch: 80/1000. Validation set: Average loss: -1.7227
Epoch: 81/1000. Train set: Average loss: -1.7717
Epoch: 81/1000. Validation set: Average loss: -1.7291
Epoch: 82/1000. Train set: Average loss: -1.7382
Epoch: 82/1000. Validation set: Average loss: -1.7416
Epoch: 83/1000. Train set: Average loss: -1.7660
Epoch: 83/1000. Validation set: Average loss: -1.7704
Epoch: 84/1000. Train set: Average loss: -1.7486
Epoch: 84/1000. Validation set: Average loss: -1.7407
Epoch: 85/1000. Train set: Average loss: -1.7618
Epoch: 85/1000. Validation set: Average loss: -1.7852
Epoch: 86/1000. Train set: Average loss: -1.7540
Epoch: 86/1000. Validation set: Average loss: -1.7753
Epoch: 87/1000. Train set: Average loss: -1.7746
Epoch: 87/1000. Validation set: Average loss: -1.7445
Epoch: 88/1000. Train set: Average loss: -1.7835
Epoch: 88/1000. Validation set: Average loss: -1.8354
Epoch: 89/1000. Train set: Average loss: -1.7817
Epoch: 89/1000. Validation set: Average loss: -1.7580
Epoch: 90/1000. Train set: Average loss: -1.7621
Epoch: 90/1000. Validation set: Average loss: -1.7878
Epoch: 91/1000. Train set: Average loss: -1.8666
Epoch: 91/1000. Validation set: Average loss: -1.8742
Epoch: 92/1000. Train set: Average loss: -1.9018
Epoch: 92/1000. Validation set: Average loss: -1.8875
Epoch: 93/1000. Train set: Average loss: -1.8486
Epoch: 93/1000. Validation set: Average loss: -1.8058
Epoch: 94/1000. Train set: Average loss: -1.8164
Epoch: 94/1000. Validation set: Average loss: -1.8173
Epoch: 95/1000. Train set: Average loss: -1.8410
Epoch: 95/1000. Validation set: Average loss: -1.8651
Epoch: 96/1000. Train set: Average loss: -1.9013
Epoch: 96/1000. Validation set: Average loss: -1.9078
Epoch: 97/1000. Train set: Average loss: -1.9289
Epoch: 97/1000. Validation set: Average loss: -1.9354
Epoch: 98/1000. Train set: Average loss: -1.9127
Epoch: 98/1000. Validation set: Average loss: -1.8550
Epoch: 99/1000. Train set: Average loss: -1.8888
Epoch: 99/1000. Validation set: Average loss: -1.9391
Epoch: 100/1000. Train set: Average loss: -1.9401
Epoch: 100/1000. Validation set: Average loss: -1.9813
Epoch: 101/1000. Train set: Average loss: -1.9965
Epoch: 101/1000. Validation set: Average loss: -1.9827
Epoch: 102/1000. Train set: Average loss: -2.0114
Epoch: 102/1000. Validation set: Average loss: -2.0225
Epoch: 103/1000. Train set: Average loss: -1.9503
Epoch: 103/1000. Validation set: Average loss: -1.9664
Epoch: 104/1000. Train set: Average loss: -1.9447
Epoch: 104/1000. Validation set: Average loss: -1.8895
Epoch: 105/1000. Train set: Average loss: -1.8995
Epoch: 105/1000. Validation set: Average loss: -1.8783
Epoch: 106/1000. Train set: Average loss: -1.8516
Epoch: 106/1000. Validation set: Average loss: -1.8467
Epoch: 107/1000. Train set: Average loss: -1.8940
Epoch: 107/1000. Validation set: Average loss: -1.9460
Epoch: 108/1000. Train set: Average loss: -1.8956
Epoch: 108/1000. Validation set: Average loss: -1.8612
Epoch: 109/1000. Train set: Average loss: -1.9551
Epoch: 109/1000. Validation set: Average loss: -2.0358
Epoch: 110/1000. Train set: Average loss: -2.0235
Epoch: 110/1000. Validation set: Average loss: -2.0024
Epoch: 111/1000. Train set: Average loss: -2.0165
Epoch: 111/1000. Validation set: Average loss: -1.9393
Epoch: 112/1000. Train set: Average loss: -2.0162
Epoch: 112/1000. Validation set: Average loss: -2.0460
Epoch: 113/1000. Train set: Average loss: -2.0178
Epoch: 113/1000. Validation set: Average loss: -1.9498
Epoch: 114/1000. Train set: Average loss: -1.9528
Epoch: 114/1000. Validation set: Average loss: -1.9925
Epoch: 115/1000. Train set: Average loss: -2.0052
Epoch: 115/1000. Validation set: Average loss: -1.9853
Epoch: 116/1000. Train set: Average loss: -1.9985
Epoch: 116/1000. Validation set: Average loss: -1.9796
Epoch: 117/1000. Train set: Average loss: -1.9921
Epoch: 117/1000. Validation set: Average loss: -2.0138
Epoch: 118/1000. Train set: Average loss: -2.0331
Epoch: 118/1000. Validation set: Average loss: -2.0423
Epoch: 119/1000. Train set: Average loss: -2.0584
Epoch: 119/1000. Validation set: Average loss: -2.0575
Epoch: 120/1000. Train set: Average loss: -2.0794
Epoch: 120/1000. Validation set: Average loss: -2.0925
Epoch: 121/1000. Train set: Average loss: -2.0875
Epoch: 121/1000. Validation set: Average loss: -2.0684
Epoch: 122/1000. Train set: Average loss: -2.0760
Epoch: 122/1000. Validation set: Average loss: -2.0330
Epoch: 123/1000. Train set: Average loss: -2.0488
Epoch: 123/1000. Validation set: Average loss: -2.0329
Epoch: 124/1000. Train set: Average loss: -2.0559
Epoch: 124/1000. Validation set: Average loss: -2.0965
Epoch: 125/1000. Train set: Average loss: -2.1201
Epoch: 125/1000. Validation set: Average loss: -2.1105
Epoch: 126/1000. Train set: Average loss: -2.1163
Epoch: 126/1000. Validation set: Average loss: -2.1096
Epoch: 127/1000. Train set: Average loss: -2.1263
Epoch: 127/1000. Validation set: Average loss: -2.1250
Epoch: 128/1000. Train set: Average loss: -2.1310
Epoch: 128/1000. Validation set: Average loss: -2.1374
Epoch: 129/1000. Train set: Average loss: -2.1428
Epoch: 129/1000. Validation set: Average loss: -2.1394
Epoch: 130/1000. Train set: Average loss: -2.1475
Epoch: 130/1000. Validation set: Average loss: -2.1391
Epoch: 131/1000. Train set: Average loss: -2.1482
Epoch: 131/1000. Validation set: Average loss: -2.1446
Epoch: 132/1000. Train set: Average loss: -2.1413
Epoch: 132/1000. Validation set: Average loss: -2.1344
Epoch: 133/1000. Train set: Average loss: -2.1439
Epoch: 133/1000. Validation set: Average loss: -2.1302
Epoch: 134/1000. Train set: Average loss: -2.1398
Epoch: 134/1000. Validation set: Average loss: -2.1301
Epoch: 135/1000. Train set: Average loss: -2.1327
Epoch: 135/1000. Validation set: Average loss: -2.1165
Epoch: 136/1000. Train set: Average loss: -2.1131
Epoch: 136/1000. Validation set: Average loss: -2.1168
Epoch: 137/1000. Train set: Average loss: -2.1213
Epoch: 137/1000. Validation set: Average loss: -2.1216
Epoch: 138/1000. Train set: Average loss: -2.1003
Epoch: 138/1000. Validation set: Average loss: -2.0692
Epoch: 139/1000. Train set: Average loss: -2.0853
Epoch: 139/1000. Validation set: Average loss: -2.0697
Epoch: 140/1000. Train set: Average loss: -2.0754
Epoch: 140/1000. Validation set: Average loss: -2.0751
yo?
Training time: 47220.51 seconds
Initial Window: tensor([[-6.6552,  0.5743, -2.0714,  4.9840,  8.8309, -1.0462,  4.6527, 10.7432],
        [-1.2573,  7.1192, 11.5621,  6.1425,  4.6180,  2.1320,  6.4135,  6.0790],
        [ 2.6308,  9.7157, 10.4960, -4.0719,  4.2621,  7.6632,  8.4280,  2.7578],
        [ 3.5314, 11.6621, -4.1574, -0.8401, -0.3725, 13.6223,  2.9777, -2.3032],
        [ 5.1709, 10.8603,  1.5052,  5.3575, 10.2030,  5.3154, -5.2997,  2.4698],
        [10.5231,  9.8095, -0.6279,  6.6502,  6.5805, -5.7486,  2.8205,  3.1672],
        [ 5.0987, -6.5853,  0.9564,  8.1044,  2.5500, -3.7802,  1.2906, 13.2256],
        [-0.7764,  0.9630, -1.0545,  8.2193,  2.7532, -1.9499, -0.7012, 13.0293],
        [ 4.3098, -1.4679,  3.2837,  9.0329, -0.0238, -0.2983,  0.3141, 12.5709],
        [-3.2271,  1.6273,  3.9535, 10.1696,  0.9897,  3.0876,  6.8140, 10.1955]])
Next 10 (9 prediction_length) steps tensor([[-3.2271,  1.6273,  3.9535, 10.1696,  0.9897,  3.0876,  6.8140, 10.1955],
        [-2.4412,  1.4171, 11.8924,  5.5080, -2.5457,  4.1696, 10.3193, -1.5410],
        [ 4.4459,  8.1026,  9.1760, -3.9613,  0.8670,  3.4818, 10.2734, -0.1379],
        [ 5.9674,  8.7886, -4.9083, -0.0667,  0.8987,  9.6319,  9.1128, -0.1576],
        [ 6.9344,  4.8333, -3.8852,  3.3546, 11.8590,  8.3064, -3.2138,  0.3050],
        [ 8.4130,  2.1772, -2.3242,  0.2615, 13.1742, -2.2076,  0.1661, -0.2565],
        [ 8.4880, -1.0374,  0.9322,  1.5652, 12.9802,  4.5080,  0.3643,  4.7071],
        [ 7.4834, -0.7099,  4.0739, 10.1310,  8.0202, -4.6900,  2.4052,  7.3596],
        [ 4.5218, -1.9389,  4.2597, 10.7186, -4.9986,  2.3751,  1.0690, 10.4754],
        [-3.4356,  0.8486,  5.4150, 10.1238,  1.6039,  6.4489, 11.1378,  0.3445]])
predicted output from the model tensor([[[ 3.3109e+00,  3.9434e+00,  3.9471e+00,  3.8162e+00,  3.6898e+00,
           3.7623e+00,  3.9019e+00,  4.0175e+00],
         [ 3.7640e+00,  3.6756e+00,  3.6775e+00,  3.7612e+00,  3.6951e+00,
           3.7214e+00,  3.6763e+00,  3.7075e+00],
         [-3.7504e+00, -2.1393e+01, -1.8433e+01, -2.1855e+01, -1.5526e+01,
          -1.8525e+01, -1.8026e+01, -1.4963e+01],
         [-3.8687e+01, -6.5798e+01, -5.2431e+01, -8.7787e+01, -7.2939e+01,
          -8.1413e+01, -5.9312e+01, -5.1098e+01],
         [-4.2403e+01, -4.6146e+01, -3.3137e+01, -7.6673e+01, -6.8329e+01,
          -7.5322e+01, -4.4893e+01, -4.1163e+01],
         [-6.0717e+01, -6.6032e+01, -4.7637e+01, -1.0938e+02, -9.7393e+01,
          -1.0728e+02, -6.4181e+01, -5.8453e+01],
         [-6.8809e+01, -7.9414e+01, -5.8371e+01, -1.2727e+02, -1.1229e+02,
          -1.2387e+02, -7.6269e+01, -6.8704e+01],
         [-6.7760e+01, -7.8523e+01, -5.7777e+01, -1.2558e+02, -1.1073e+02,
          -1.2217e+02, -7.5356e+01, -6.7848e+01],
         [-4.9151e+01, -4.0085e+01, -2.5765e+01, -7.9044e+01, -7.3562e+01,
          -8.0396e+01, -4.1693e+01, -3.9918e+01],
         [-5.0929e+01, -3.4150e+01, -1.9755e+01, -7.6523e+01, -7.3163e+01,
          -7.9542e+01, -3.7492e+01, -3.7090e+01]],

        [[ 3.3517e+00,  3.7888e+00,  3.7899e+00,  3.7181e+00,  3.6035e+00,
           3.6717e+00,  3.7627e+00,  3.8520e+00],
         [ 3.8162e+00,  3.3974e+00,  3.4056e+00,  3.5816e+00,  3.5466e+00,
           3.5547e+00,  3.4306e+00,  3.4143e+00],
         [ 3.9997e+00,  3.0132e+00,  3.0439e+00,  3.3618e+00,  3.3982e+00,
           3.3305e+00,  3.1019e+00,  2.9868e+00],
         [ 3.8951e+00,  3.5041e+00,  3.5572e+00,  3.6666e+00,  3.6867e+00,
           3.6077e+00,  3.5351e+00,  3.5001e+00],
         [ 3.7620e+00,  3.9657e+00,  4.0071e+00,  3.9351e+00,  3.9029e+00,
           3.8472e+00,  3.9418e+00,  3.9823e+00],
         [-2.3250e+00, -1.8075e+01, -1.5632e+01, -1.8135e+01, -1.2625e+01,
          -1.5242e+01, -1.5216e+01, -1.2501e+01],
         [-4.0004e+01, -7.6303e+01, -6.1988e+01, -9.7063e+01, -7.9209e+01,
          -8.8727e+01, -6.7706e+01, -5.7588e+01],
         [-3.3572e+01, -3.7525e+01, -2.7030e+01, -6.1646e+01, -5.4776e+01,
          -6.0457e+01, -3.6360e+01, -3.3412e+01],
         [-6.8614e+01, -9.2811e+01, -7.0985e+01, -1.3717e+02, -1.1808e+02,
          -1.3088e+02, -8.6619e+01, -7.6277e+01],
         [-5.2979e+01, -5.7218e+01, -4.1106e+01, -9.5268e+01, -8.4955e+01,
          -9.3584e+01, -5.5726e+01, -5.0937e+01]],

        [[ 3.4277e+00,  3.5016e+00,  3.4978e+00,  3.5361e+00,  3.4439e+00,
           3.5032e+00,  3.5042e+00,  3.5444e+00],
         [ 3.3732e+00,  5.0702e+00,  5.1470e+00,  4.6419e+00,  4.5399e+00,
           4.5219e+00,  4.9281e+00,  5.1926e+00],
         [ 3.9023e+00,  3.8400e+00,  3.7976e+00,  3.8945e+00,  3.7998e+00,
           3.8426e+00,  3.8240e+00,  3.8591e+00],
         [ 4.1901e+00,  2.4860e+00,  2.5337e+00,  3.0206e+00,  3.1708e+00,
           3.0029e+00,  2.6768e+00,  2.4590e+00],
         [ 3.6992e+00, -1.6549e+00, -1.1967e+00, -3.9849e-01,  9.3918e-01,
           1.9364e-01, -8.1162e-01, -4.0780e-01],
         [ 3.6882e+00, -1.8643e+00, -1.4300e+00, -5.9398e-01,  8.2851e-01,
           4.1505e-02, -1.1534e+00, -7.2029e-01],
         [ 3.6624e+00, -9.9062e-01, -5.9147e-01,  5.7301e-02,  1.2534e+00,
           5.9875e-01, -4.2283e-01, -1.3328e-02],
         [-8.2491e-01, -1.6170e+01, -1.4166e+01, -1.5052e+01, -9.7703e+00,
          -1.2225e+01, -1.3549e+01, -1.0926e+01],
         [-2.9446e+01, -5.6834e+01, -4.6073e+01, -7.2103e+01, -5.8801e+01,
          -6.5917e+01, -5.0432e+01, -4.3062e+01],
         [-5.1932e+01, -7.8081e+01, -6.0961e+01, -1.0990e+02, -9.3082e+01,
          -1.0353e+02, -7.1681e+01, -6.2424e+01]]], device='cuda:0',
       grad_fn=<CatBackward0>) torch.Size([3, 10, 8])
-2.0891813345394303
